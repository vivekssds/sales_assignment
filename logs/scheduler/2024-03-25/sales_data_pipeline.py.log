[2024-03-25T14:52:02.849+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:52:02.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:52:02.851+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:52:02.850+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:52:03.416+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:52:03.415+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:52:03.417+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:52:03.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.583 seconds
[2024-03-25T14:52:34.215+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:52:34.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:52:34.217+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:52:34.217+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:52:34.418+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:52:34.415+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:52:34.419+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:52:34.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.222 seconds
[2024-03-25T14:53:04.517+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:53:04.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:53:04.519+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:53:04.518+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:53:04.650+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:53:04.649+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:53:04.651+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:53:04.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.148 seconds
[2024-03-25T14:53:34.801+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:53:34.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:53:34.804+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:53:34.804+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:53:34.974+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:53:34.972+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:53:34.974+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:53:34.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.190 seconds
[2024-03-25T14:54:05.074+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:54:05.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:54:05.076+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:54:05.076+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:54:05.225+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:54:05.223+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:54:05.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:54:05.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.169 seconds
[2024-03-25T14:54:35.304+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:54:35.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:54:35.306+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:54:35.306+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:54:35.463+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:54:35.462+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:54:35.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:54:35.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T14:55:05.624+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:55:05.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:55:05.625+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:55:05.625+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:55:05.777+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:55:05.768+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:55:05.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:55:05.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T14:55:35.831+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:55:35.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:55:35.832+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:55:35.832+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:55:35.965+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:55:35.964+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:55:35.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:55:35.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.150 seconds
[2024-03-25T14:56:06.136+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:56:06.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:56:06.138+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:56:06.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:56:06.293+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:56:06.291+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:56:06.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:56:06.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T14:56:36.461+0000] {processor.py:161} INFO - Started process (PID=474) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:56:36.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:56:36.462+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:56:36.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:56:36.618+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:56:36.616+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:56:36.619+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:56:36.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T14:57:06.681+0000] {processor.py:161} INFO - Started process (PID=501) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:57:06.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:57:06.682+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:57:06.682+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:57:06.835+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:57:06.833+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:57:06.835+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:57:06.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.169 seconds
[2024-03-25T14:57:36.982+0000] {processor.py:161} INFO - Started process (PID=536) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:57:36.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:57:36.984+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:57:36.984+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:57:37.136+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:57:37.134+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:57:37.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:57:37.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.170 seconds
[2024-03-25T14:58:07.188+0000] {processor.py:161} INFO - Started process (PID=571) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:58:07.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:58:07.189+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:58:07.189+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:58:07.331+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:58:07.329+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:58:07.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:58:07.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.159 seconds
[2024-03-25T14:58:37.488+0000] {processor.py:161} INFO - Started process (PID=598) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:58:37.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:58:37.491+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:58:37.490+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:58:37.639+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:58:37.637+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:58:37.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:58:37.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.167 seconds
[2024-03-25T14:59:07.709+0000] {processor.py:161} INFO - Started process (PID=633) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:59:07.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:59:07.711+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:59:07.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:59:07.896+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:59:07.893+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:59:07.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:59:07.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.206 seconds
[2024-03-25T14:59:37.951+0000] {processor.py:161} INFO - Started process (PID=668) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:59:37.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T14:59:37.953+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:59:37.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:59:38.107+0000] {logging_mixin.py:188} INFO - [2024-03-25T14:59:38.105+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T14:59:38.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T14:59:38.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T15:00:08.260+0000] {processor.py:161} INFO - Started process (PID=702) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:00:08.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:00:08.262+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:00:08.261+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:00:08.421+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:00:08.418+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:00:08.421+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:00:08.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T15:00:38.472+0000] {processor.py:161} INFO - Started process (PID=730) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:00:38.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:00:38.474+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:00:38.474+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:00:38.611+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:00:38.609+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:00:38.611+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:00:38.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.156 seconds
[2024-03-25T15:02:27.127+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:02:27.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:02:27.129+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:02:27.128+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:02:27.672+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:02:27.670+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:02:27.672+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:02:27.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.560 seconds
[2024-03-25T15:02:58.486+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:02:58.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:02:58.488+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:02:58.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:02:58.642+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:02:58.640+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:02:58.643+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:02:58.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T15:03:28.753+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:03:28.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:03:28.755+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:03:28.755+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:03:28.914+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:03:28.912+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:03:28.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:03:28.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T15:03:59.159+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:03:59.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:03:59.162+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:03:59.161+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:03:59.311+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:03:59.309+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:03:59.312+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:03:59.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.169 seconds
[2024-03-25T15:04:29.373+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:04:29.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:04:29.374+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:04:29.374+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:04:29.508+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:04:29.506+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:04:29.508+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:04:29.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.150 seconds
[2024-03-25T15:04:59.704+0000] {processor.py:161} INFO - Started process (PID=341) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:04:59.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:04:59.708+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:04:59.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:04:59.858+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:04:59.856+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:04:59.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:04:59.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T15:05:29.932+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:05:29.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:05:29.934+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:05:29.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:05:30.080+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:05:30.078+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:05:30.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:05:30.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.165 seconds
[2024-03-25T15:06:00.281+0000] {processor.py:161} INFO - Started process (PID=403) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:06:00.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:06:00.283+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:06:00.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:06:00.427+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:06:00.425+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:06:00.427+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:06:00.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.161 seconds
[2024-03-25T15:06:30.489+0000] {processor.py:161} INFO - Started process (PID=438) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:06:30.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:06:30.491+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:06:30.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:06:30.637+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:06:30.635+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:06:30.637+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:06:30.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.164 seconds
[2024-03-25T15:07:00.809+0000] {processor.py:161} INFO - Started process (PID=473) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:07:00.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:07:00.810+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:07:00.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:07:00.946+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:07:00.944+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:07:00.946+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:07:00.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.152 seconds
[2024-03-25T15:07:31.073+0000] {processor.py:161} INFO - Started process (PID=508) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:07:31.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:07:31.076+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:07:31.075+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:07:31.218+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:07:31.216+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:07:31.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:07:31.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.161 seconds
[2024-03-25T15:08:01.365+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:08:01.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:08:01.368+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:08:01.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:08:01.514+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:08:01.512+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:08:01.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:08:01.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.165 seconds
[2024-03-25T15:08:31.621+0000] {processor.py:161} INFO - Started process (PID=578) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:08:31.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:08:31.623+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:08:31.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:08:31.778+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:08:31.776+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:08:31.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:08:31.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.176 seconds
[2024-03-25T15:09:01.887+0000] {processor.py:161} INFO - Started process (PID=605) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:09:01.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:09:01.889+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:09:01.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:09:02.041+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:09:02.039+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/datasource/sales_data.csv'
[2024-03-25T15:09:02.041+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:09:02.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.169 seconds
[2024-03-25T15:09:32.133+0000] {processor.py:161} INFO - Started process (PID=640) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:09:32.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:09:32.135+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:09:32.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:09:32.295+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:09:32.293+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:09:32.296+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:09:32.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.180 seconds
[2024-03-25T15:10:02.387+0000] {processor.py:161} INFO - Started process (PID=675) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:10:02.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:10:02.389+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:10:02.388+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:10:02.548+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:10:02.546+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:10:02.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:10:02.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.178 seconds
[2024-03-25T15:10:32.640+0000] {processor.py:161} INFO - Started process (PID=710) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:10:32.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:10:32.642+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:10:32.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:10:32.796+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:10:32.794+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:10:32.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:10:32.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T15:11:02.851+0000] {processor.py:161} INFO - Started process (PID=737) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:11:02.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:11:02.855+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:11:02.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:11:02.997+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:11:02.995+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:11:02.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:11:03.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T15:11:33.185+0000] {processor.py:161} INFO - Started process (PID=772) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:11:33.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:11:33.186+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:11:33.186+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:11:33.325+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:11:33.323+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:11:33.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:11:33.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T15:12:03.471+0000] {processor.py:161} INFO - Started process (PID=807) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:12:03.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:12:03.473+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:12:03.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:12:03.635+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:12:03.633+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:12:03.636+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:12:03.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.180 seconds
[2024-03-25T15:12:33.876+0000] {processor.py:161} INFO - Started process (PID=834) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:12:33.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:12:33.879+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:12:33.878+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:12:34.038+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:12:34.036+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:12:34.039+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:12:34.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.179 seconds
[2024-03-25T15:13:04.140+0000] {processor.py:161} INFO - Started process (PID=868) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:13:04.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:13:04.142+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:13:04.141+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:13:04.271+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:13:04.269+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:13:04.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:13:04.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.146 seconds
[2024-03-25T15:13:34.409+0000] {processor.py:161} INFO - Started process (PID=903) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:13:34.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:13:34.412+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:13:34.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:13:34.578+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:13:34.576+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:13:34.578+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:13:34.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.186 seconds
[2024-03-25T15:14:04.753+0000] {processor.py:161} INFO - Started process (PID=938) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:14:04.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:14:04.754+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:14:04.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:14:04.900+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:14:04.898+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:14:04.901+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:14:04.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.165 seconds
[2024-03-25T15:14:35.080+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:14:35.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:14:35.083+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:14:35.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:14:35.232+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:14:35.229+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:14:35.232+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:14:35.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T15:15:05.324+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:15:05.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:15:05.327+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:15:05.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:15:05.476+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:15:05.474+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:15:05.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:15:05.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.169 seconds
[2024-03-25T15:15:35.546+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:15:35.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:15:35.548+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:15:35.548+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:15:35.702+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:15:35.700+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:15:35.703+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:15:35.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T15:16:05.794+0000] {processor.py:161} INFO - Started process (PID=1062) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:16:05.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:16:05.796+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:16:05.796+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:16:05.958+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:16:05.956+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:16:05.958+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:16:05.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.180 seconds
[2024-03-25T15:16:36.021+0000] {processor.py:161} INFO - Started process (PID=1097) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:16:36.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:16:36.023+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:16:36.023+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:16:36.174+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:16:36.171+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:16:36.174+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:16:36.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.170 seconds
[2024-03-25T15:17:06.320+0000] {processor.py:161} INFO - Started process (PID=1133) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:17:06.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:17:06.322+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:17:06.322+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:17:06.454+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:17:06.452+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:17:06.454+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:17:06.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.149 seconds
[2024-03-25T15:17:36.552+0000] {processor.py:161} INFO - Started process (PID=1168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:17:36.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:17:36.553+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:17:36.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:17:36.698+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:17:36.696+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:17:36.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:17:36.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.161 seconds
[2024-03-25T15:18:06.884+0000] {processor.py:161} INFO - Started process (PID=1196) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:18:06.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:18:06.885+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:18:06.885+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:18:07.056+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:18:07.054+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:18:07.057+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:18:07.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.189 seconds
[2024-03-25T15:18:37.189+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:18:37.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:18:37.191+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:18:37.191+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:18:37.335+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:18:37.333+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:18:37.335+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:18:37.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T15:19:07.475+0000] {processor.py:161} INFO - Started process (PID=1267) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:19:07.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:19:07.477+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:19:07.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:19:07.646+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:19:07.644+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:19:07.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:19:07.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.188 seconds
[2024-03-25T15:19:37.697+0000] {processor.py:161} INFO - Started process (PID=1294) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:19:37.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:19:37.699+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:19:37.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:19:37.853+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:19:37.851+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:19:37.853+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:19:37.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T15:20:08.045+0000] {processor.py:161} INFO - Started process (PID=1329) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:20:08.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:20:08.047+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:20:08.047+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:20:08.181+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:20:08.180+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:20:08.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:20:08.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.152 seconds
[2024-03-25T15:20:38.365+0000] {processor.py:161} INFO - Started process (PID=1364) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:20:38.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:20:38.367+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:20:38.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:20:38.521+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:20:38.519+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:20:38.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:20:38.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T15:21:08.679+0000] {processor.py:161} INFO - Started process (PID=1399) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:21:08.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:21:08.681+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:21:08.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:21:08.827+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:21:08.825+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:21:08.828+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:21:08.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T15:21:39.006+0000] {processor.py:161} INFO - Started process (PID=1426) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:21:39.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:21:39.007+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:21:39.007+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:21:39.128+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:21:39.126+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:21:39.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:21:39.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.137 seconds
[2024-03-25T15:22:09.303+0000] {processor.py:161} INFO - Started process (PID=1462) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:22:09.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:22:09.306+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:22:09.305+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:22:09.434+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:22:09.432+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:22:09.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:22:09.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.147 seconds
[2024-03-25T15:22:39.541+0000] {processor.py:161} INFO - Started process (PID=1497) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:22:39.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:22:39.542+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:22:39.542+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:22:39.679+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:22:39.678+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:22:39.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:22:39.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.154 seconds
[2024-03-25T15:23:09.871+0000] {processor.py:161} INFO - Started process (PID=1524) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:23:09.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:23:09.874+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:23:09.873+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:23:10.028+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:23:10.026+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:23:10.029+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:23:10.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.174 seconds
[2024-03-25T15:23:40.160+0000] {processor.py:161} INFO - Started process (PID=1559) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:23:40.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:23:40.162+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:23:40.161+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:23:40.292+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:23:40.290+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:23:40.292+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:23:40.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.147 seconds
[2024-03-25T15:24:10.433+0000] {processor.py:161} INFO - Started process (PID=1594) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:24:10.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:24:10.435+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:24:10.435+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:24:10.572+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:24:10.570+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:24:10.572+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:24:10.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T15:24:40.764+0000] {processor.py:161} INFO - Started process (PID=1628) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:24:40.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:24:40.766+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:24:40.766+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:24:40.921+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:24:40.919+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:24:40.922+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:24:40.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.174 seconds
[2024-03-25T15:25:11.090+0000] {processor.py:161} INFO - Started process (PID=1655) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:25:11.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:25:11.092+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:25:11.091+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:25:11.226+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:25:11.224+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:25:11.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:25:11.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T15:25:41.361+0000] {processor.py:161} INFO - Started process (PID=1690) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:25:41.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:25:41.362+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:25:41.362+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:25:41.499+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:25:41.497+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:25:41.499+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:25:41.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.153 seconds
[2024-03-25T15:26:11.580+0000] {processor.py:161} INFO - Started process (PID=1725) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:26:11.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:26:11.583+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:26:11.582+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:26:11.721+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:26:11.719+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:26:11.721+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:26:11.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.157 seconds
[2024-03-25T15:26:41.879+0000] {processor.py:161} INFO - Started process (PID=1760) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:26:41.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:26:41.881+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:26:41.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:26:42.053+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:26:42.051+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:26:42.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:26:42.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.188 seconds
[2024-03-25T15:27:12.192+0000] {processor.py:161} INFO - Started process (PID=1787) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:27:12.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:27:12.195+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:27:12.194+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:27:12.331+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:27:12.329+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:27:12.332+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:27:12.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.156 seconds
[2024-03-25T15:27:42.475+0000] {processor.py:161} INFO - Started process (PID=1822) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:27:42.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:27:42.477+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:27:42.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:27:42.631+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:27:42.629+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:27:42.632+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:27:42.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T15:28:12.772+0000] {processor.py:161} INFO - Started process (PID=1857) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:28:12.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:28:12.775+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:28:12.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:28:12.923+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:28:12.921+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:28:12.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:28:12.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T15:28:43.151+0000] {processor.py:161} INFO - Started process (PID=1884) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:28:43.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:28:43.152+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:28:43.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:28:43.309+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:28:43.307+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:28:43.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:28:43.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.174 seconds
[2024-03-25T15:29:13.487+0000] {processor.py:161} INFO - Started process (PID=1919) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:29:13.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:29:13.488+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:29:13.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:29:13.613+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:29:13.612+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:29:13.614+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:29:13.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.141 seconds
[2024-03-25T15:29:43.766+0000] {processor.py:161} INFO - Started process (PID=1954) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:29:43.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:29:43.770+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:29:43.770+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:29:43.930+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:29:43.928+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:29:43.930+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:29:43.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.182 seconds
[2024-03-25T15:30:14.154+0000] {processor.py:161} INFO - Started process (PID=1989) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:30:14.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:30:14.156+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:30:14.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:30:14.297+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:30:14.295+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:30:14.297+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:30:14.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.158 seconds
[2024-03-25T15:30:44.466+0000] {processor.py:161} INFO - Started process (PID=2016) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:30:44.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:30:44.469+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:30:44.468+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:30:44.620+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:30:44.618+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:30:44.620+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:30:44.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T15:31:14.775+0000] {processor.py:161} INFO - Started process (PID=2051) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:31:14.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:31:14.779+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:31:14.778+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:31:15.124+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:31:15.121+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:31:15.124+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:31:15.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.367 seconds
[2024-03-25T15:31:46.083+0000] {processor.py:161} INFO - Started process (PID=2086) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:31:46.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:31:46.086+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:31:46.085+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:31:46.236+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:31:46.234+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:31:46.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:31:46.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T15:32:16.374+0000] {processor.py:161} INFO - Started process (PID=2121) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:32:16.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:32:16.376+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:32:16.375+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:32:16.535+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:32:16.533+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:32:16.535+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:32:16.547+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T15:32:46.602+0000] {processor.py:161} INFO - Started process (PID=2148) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:32:46.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:32:46.605+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:32:46.604+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:32:46.776+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:32:46.773+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:32:46.776+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:32:46.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.192 seconds
[2024-03-25T15:33:16.973+0000] {processor.py:161} INFO - Started process (PID=2183) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:33:16.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:33:16.976+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:33:16.975+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:33:17.130+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:33:17.128+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:33:17.130+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:33:17.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.173 seconds
[2024-03-25T15:33:47.207+0000] {processor.py:161} INFO - Started process (PID=2218) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:33:47.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:33:47.211+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:33:47.211+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:33:47.373+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:33:47.371+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:33:47.373+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:33:47.385+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.184 seconds
[2024-03-25T15:35:19.432+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:35:19.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:35:19.433+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:35:19.433+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:35:20.006+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:35:20.004+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:35:20.006+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:35:20.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.589 seconds
[2024-03-25T15:35:50.810+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:35:50.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:35:50.812+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:35:50.812+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:35:50.988+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:35:50.986+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:35:50.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:35:51.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.196 seconds
[2024-03-25T15:36:21.049+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:36:21.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:36:21.050+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:36:21.050+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:36:21.202+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:36:21.200+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:36:21.202+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:36:21.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.170 seconds
[2024-03-25T15:36:51.365+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:36:51.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:36:51.368+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:36:51.368+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:36:51.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:36:51.530+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:36:51.533+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:36:51.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.185 seconds
[2024-03-25T15:37:21.585+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:37:21.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:37:21.587+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:37:21.587+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:37:21.720+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:37:21.718+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:37:21.720+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:37:21.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.150 seconds
[2024-03-25T15:37:51.924+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:37:51.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:37:51.925+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:37:51.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:37:52.080+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:37:52.078+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:37:52.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:37:52.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T15:38:22.308+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:38:22.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:38:22.312+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:38:22.311+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:38:22.478+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:38:22.476+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:38:22.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:38:22.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.186 seconds
[2024-03-25T15:38:52.593+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:38:52.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:38:52.596+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:38:52.596+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:38:52.735+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:38:52.733+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:38:52.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:38:52.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.162 seconds
[2024-03-25T15:39:22.881+0000] {processor.py:161} INFO - Started process (PID=441) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:39:22.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:39:22.884+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:39:22.884+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:39:23.058+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:39:23.056+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:39:23.058+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:39:23.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.197 seconds
[2024-03-25T15:39:53.235+0000] {processor.py:161} INFO - Started process (PID=476) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:39:53.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:39:53.237+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:39:53.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:39:53.373+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:39:53.371+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:39:53.373+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:39:53.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.154 seconds
[2024-03-25T15:40:23.489+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:40:23.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:40:23.491+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:40:23.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:40:23.648+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:40:23.646+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:40:23.648+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:40:23.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T15:40:53.699+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:40:53.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:40:53.700+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:40:53.700+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:40:53.847+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:40:53.846+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:40:53.848+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:40:53.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.167 seconds
[2024-03-25T15:41:23.945+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:41:23.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:41:23.948+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:41:23.947+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:41:24.107+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:41:24.105+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:41:24.107+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:41:24.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.179 seconds
[2024-03-25T15:41:54.183+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:41:54.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:41:54.187+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:41:54.187+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:41:54.331+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:41:54.330+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:41:54.332+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:41:54.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.165 seconds
[2024-03-25T15:42:24.470+0000] {processor.py:161} INFO - Started process (PID=635) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:42:24.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:42:24.472+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:42:24.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:42:24.630+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:42:24.628+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:42:24.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:42:24.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T15:42:54.696+0000] {processor.py:161} INFO - Started process (PID=670) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:42:54.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:42:54.699+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:42:54.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:42:54.843+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:42:54.841+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:42:54.844+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:42:54.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.164 seconds
[2024-03-25T15:43:25.072+0000] {processor.py:161} INFO - Started process (PID=705) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:43:25.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:43:25.074+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:43:25.074+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:43:25.228+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:43:25.226+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:43:25.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:43:25.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.173 seconds
[2024-03-25T15:43:55.436+0000] {processor.py:161} INFO - Started process (PID=732) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:43:55.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:43:55.440+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:43:55.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:43:55.586+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:43:55.583+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:43:55.586+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:43:55.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.167 seconds
[2024-03-25T15:44:25.753+0000] {processor.py:161} INFO - Started process (PID=767) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:44:25.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:44:25.756+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:44:25.755+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:44:25.939+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:44:25.936+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:44:25.939+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:44:25.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.203 seconds
[2024-03-25T15:44:56.018+0000] {processor.py:161} INFO - Started process (PID=802) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:44:56.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:44:56.020+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:44:56.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:44:56.156+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:44:56.154+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/sales_data.csv'
[2024-03-25T15:44:56.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:44:56.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T15:45:26.357+0000] {processor.py:161} INFO - Started process (PID=829) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:45:26.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:45:26.360+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:45:26.359+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:45:26.550+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:45:26.547+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:45:26.550+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:45:26.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.214 seconds
[2024-03-25T15:45:56.636+0000] {processor.py:161} INFO - Started process (PID=864) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:45:56.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:45:56.638+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:45:56.638+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:45:56.808+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:45:56.806+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:45:56.809+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:45:56.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.197 seconds
[2024-03-25T15:49:32.094+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:49:32.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:49:32.096+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:49:32.096+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:49:32.704+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:49:32.702+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:49:32.704+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:49:32.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.626 seconds
[2024-03-25T15:50:03.435+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:50:03.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:50:03.438+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:50:03.438+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:50:03.596+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:50:03.592+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path.format(DQ_DIR=DQ_DIR))
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:50:03.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:50:03.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T15:50:33.731+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:50:33.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:50:33.734+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:50:33.733+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:50:33.891+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:50:33.889+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:50:33.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:50:33.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.176 seconds
[2024-03-25T15:51:04.089+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:51:04.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:51:04.092+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:51:04.091+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:51:04.234+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:51:04.232+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:51:04.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:51:04.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.162 seconds
[2024-03-25T15:51:34.382+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:51:34.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:51:34.385+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:51:34.384+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:51:34.560+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:51:34.557+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:51:34.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:51:34.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.194 seconds
[2024-03-25T15:52:04.650+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:52:04.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:52:04.652+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:52:04.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:52:04.783+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:52:04.782+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 11, in build_exec_pipeline_sales_data
    sales_data_df = get_sales_data_from_csv()
  File "/opt/airflow/dags/common.py", line 27, in get_sales_data_from_csv
    sales_data_df = pd.read_csv(csv_file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/var/lib/mysql-files/sales_data.csv'
[2024-03-25T15:52:04.784+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:52:04.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.150 seconds
[2024-03-25T15:52:43.600+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:52:43.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:52:43.602+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:52:43.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:52:48.522+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:52:48.521+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:52:48.537+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:52:48.536+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T15:52:48.538+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:52:48.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.946 seconds
[2024-03-25T15:53:19.039+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:53:19.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:53:19.042+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:19.041+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:53:23.186+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:23.186+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:53:23.200+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:23.198+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T15:53:23.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:53:23.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.172 seconds
[2024-03-25T15:53:53.326+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:53:53.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:53:53.328+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:53.328+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:53:57.497+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:57.496+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:53:57.507+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:57.507+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:53:57.509+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:57.509+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:53:57.510+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:57.510+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:53:57.518+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:53:57.516+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:53:57.518+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:53:57.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.199 seconds
[2024-03-25T15:54:27.555+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:54:27.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:54:27.557+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:54:27.557+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:54:31.824+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:54:31.822+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:54:31.850+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:54:31.850+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:54:31.852+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:54:31.852+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:54:31.854+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:54:31.854+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:54:31.861+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:54:31.858+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:54:31.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:54:31.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.316 seconds
[2024-03-25T15:55:01.905+0000] {processor.py:161} INFO - Started process (PID=310) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:55:01.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:55:01.906+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:01.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:55:06.190+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:06.188+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:55:06.215+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:06.215+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:55:06.217+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:06.217+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:55:06.219+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:06.218+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:55:06.225+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:06.222+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:55:06.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:55:06.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.330 seconds
[2024-03-25T15:55:37.237+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:55:37.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:55:37.239+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:37.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:55:41.506+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:41.504+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:55:41.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:41.533+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:55:41.535+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:41.535+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:55:41.537+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:41.537+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:55:41.546+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:55:41.543+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:55:41.547+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:55:41.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.321 seconds
[2024-03-25T15:56:12.549+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:56:12.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:56:12.552+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:12.552+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:56:16.799+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:16.798+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:56:16.835+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:16.835+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:56:16.838+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:16.837+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:56:16.839+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:16.839+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:56:16.845+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:16.843+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:56:16.846+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:56:16.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.305 seconds
[2024-03-25T15:56:46.945+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:56:46.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:56:46.947+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:46.946+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:56:51.156+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:51.154+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:56:51.182+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:51.182+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:56:51.184+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:51.184+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:56:51.186+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:51.186+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:56:51.192+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:56:51.190+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:56:51.193+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:56:51.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.256 seconds
[2024-03-25T15:57:21.374+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:57:21.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:57:21.377+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:21.376+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:57:25.506+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:25.505+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:57:25.524+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:25.524+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:57:25.526+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:25.525+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:57:25.527+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:25.527+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:57:25.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:25.531+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:57:25.534+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:57:25.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.168 seconds
[2024-03-25T15:57:55.591+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:57:55.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:57:55.593+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:55.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:57:59.831+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:59.830+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:57:59.844+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:59.844+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:57:59.845+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:59.845+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:57:59.846+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:59.846+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:57:59.852+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:57:59.850+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:57:59.853+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:57:59.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.273 seconds
[2024-03-25T15:58:29.911+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:58:29.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:58:29.913+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:58:29.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:58:34.242+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:58:34.241+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:58:34.253+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:58:34.253+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:58:34.254+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:58:34.254+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:58:34.255+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:58:34.255+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:58:34.260+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:58:34.258+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:58:34.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:58:34.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.358 seconds
[2024-03-25T15:59:05.157+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:59:05.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:59:05.159+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:05.159+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:59:09.214+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:09.214+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:59:09.229+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:09.229+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:59:09.230+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:09.230+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:59:09.232+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:09.232+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:59:09.236+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:09.235+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:59:09.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:59:09.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.089 seconds
[2024-03-25T15:59:39.448+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:59:39.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T15:59:39.450+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:39.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:59:44.760+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:44.759+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:59:44.781+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:44.781+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:59:44.783+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:44.783+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T15:59:44.784+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:44.784+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T15:59:44.794+0000] {logging_mixin.py:188} INFO - [2024-03-25T15:59:44.791+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T15:59:44.795+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T15:59:44.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.369 seconds
[2024-03-25T16:00:15.673+0000] {processor.py:161} INFO - Started process (PID=637) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:00:15.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:00:15.675+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:15.675+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:00:20.445+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:20.444+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:00:20.463+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:20.463+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:00:20.465+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:20.465+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:00:20.467+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:20.467+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:00:20.474+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:20.472+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:00:20.475+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:00:20.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.811 seconds
[2024-03-25T16:00:50.931+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:00:50.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:00:50.933+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:50.933+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:00:55.247+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:55.246+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:00:55.269+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:55.269+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:00:55.271+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:55.271+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:00:55.272+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:55.272+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:00:55.280+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:00:55.277+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:00:55.281+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:00:55.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.359 seconds
[2024-03-25T16:01:26.203+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:01:26.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:01:26.205+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:01:26.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:01:30.423+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:01:30.423+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:01:30.434+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:01:30.434+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:01:30.435+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:01:30.435+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:01:30.436+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:01:30.436+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:01:30.440+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:01:30.439+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:01:30.441+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:01:30.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.245 seconds
[2024-03-25T16:02:00.497+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:02:00.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:02:00.500+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:00.500+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:02:04.760+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:04.758+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:02:04.787+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:04.787+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:02:04.790+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:04.790+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:02:04.792+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:04.792+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:02:04.800+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:04.798+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:02:04.801+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:02:04.806+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.313 seconds
[2024-03-25T16:02:35.746+0000] {processor.py:161} INFO - Started process (PID=790) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:02:35.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:02:35.750+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:35.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:02:39.939+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:39.938+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:02:39.957+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:39.957+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:02:39.959+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:39.958+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:02:39.961+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:39.960+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:02:39.968+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:02:39.965+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:02:39.968+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:02:39.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.238 seconds
[2024-03-25T16:03:10.976+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:03:10.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:03:10.978+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:10.977+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:03:14.984+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:14.983+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:03:14.998+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:14.998+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:03:15.001+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:15.001+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:03:15.006+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:15.006+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:03:15.019+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:15.009+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:03:15.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:03:15.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.055 seconds
[2024-03-25T16:03:45.230+0000] {processor.py:161} INFO - Started process (PID=860) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:03:45.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:03:45.233+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:45.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:03:49.520+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:49.520+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:03:49.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:49.533+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:03:49.534+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:49.534+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:03:49.535+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:49.535+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:03:49.540+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:03:49.538+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:03:49.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:03:49.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.318 seconds
[2024-03-25T16:04:19.590+0000] {processor.py:161} INFO - Started process (PID=900) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:04:19.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:04:19.592+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:19.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:04:23.772+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:23.771+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:04:23.789+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:23.788+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:04:23.790+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:23.790+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:04:23.792+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:23.792+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:04:23.799+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:23.796+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:04:23.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:04:23.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.219 seconds
[2024-03-25T16:04:53.909+0000] {processor.py:161} INFO - Started process (PID=935) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:04:53.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:04:53.911+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:53.911+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:04:58.019+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:58.018+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:04:58.031+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:58.031+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:04:58.032+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:58.032+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:04:58.033+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:58.033+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:04:58.038+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:04:58.036+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:04:58.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:04:58.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.138 seconds
[2024-03-25T16:05:28.106+0000] {processor.py:161} INFO - Started process (PID=970) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:05:28.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:05:28.109+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:05:28.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:05:32.407+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:05:32.406+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:05:32.423+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:05:32.423+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:05:32.424+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:05:32.424+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:05:32.426+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:05:32.425+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:05:32.432+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:05:32.430+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:05:32.432+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:05:32.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.338 seconds
[2024-03-25T16:06:03.358+0000] {processor.py:161} INFO - Started process (PID=1005) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:06:03.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:06:03.360+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:06:03.359+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:06:07.623+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:06:07.622+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:06:07.636+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:06:07.636+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:06:07.638+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:06:07.637+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:06:07.640+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:06:07.640+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:06:07.645+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:06:07.643+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:06:07.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:06:07.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.297 seconds
[2024-03-25T16:09:41.168+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:09:41.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:09:41.170+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:09:41.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:09:45.764+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:09:45.764+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:09:45.785+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:09:45.780+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:09:45.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:09:45.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.633 seconds
[2024-03-25T16:10:16.508+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:10:16.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:10:16.510+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:16.510+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:10:20.663+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:20.662+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:10:20.687+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:20.684+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:10:20.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:10:20.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.188 seconds
[2024-03-25T16:10:50.831+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:10:50.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:10:50.833+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:50.833+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:10:54.936+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:54.934+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:10:54.959+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:54.959+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:10:54.962+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:54.962+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:10:54.964+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:54.964+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:10:54.977+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:10:54.974+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:10:54.977+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:10:54.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.156 seconds
[2024-03-25T16:13:28.416+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:13:28.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:13:28.418+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:13:28.417+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:13:32.936+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:13:32.935+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:13:32.948+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:13:32.947+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:13:32.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:13:32.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.540 seconds
[2024-03-25T16:14:03.859+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:14:03.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:14:03.861+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:03.861+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:14:08.104+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:08.103+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:14:08.121+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:08.119+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:14:08.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:14:08.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.272 seconds
[2024-03-25T16:14:38.177+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:14:38.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:14:38.182+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:38.181+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:14:42.373+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:42.372+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:14:42.391+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:42.391+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:14:42.393+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:42.392+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:14:42.394+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:42.394+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:14:42.405+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:14:42.403+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:14:42.406+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:14:42.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.239 seconds
[2024-03-25T16:15:12.489+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:15:12.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:15:12.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:12.493+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:15:16.704+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:16.703+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:15:16.731+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:16.730+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:15:16.732+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:16.732+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:15:16.734+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:16.734+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:15:16.740+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:16.738+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:15:16.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:15:16.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.266 seconds
[2024-03-25T16:15:46.779+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:15:46.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:15:46.781+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:46.780+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:15:50.971+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:50.970+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:15:50.987+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:50.987+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:15:50.988+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:50.988+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:15:50.990+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:50.989+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:15:50.995+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:15:50.992+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:15:50.995+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:15:50.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.223 seconds
[2024-03-25T16:16:21.073+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:16:21.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:16:21.075+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:16:21.074+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:16:26.381+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:16:26.380+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:16:26.404+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:16:26.404+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:16:26.405+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:16:26.405+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:16:26.407+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:16:26.407+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:16:26.412+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:16:26.410+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:16:26.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:16:26.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.349 seconds
[2024-03-25T16:16:57.367+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:16:57.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:16:57.369+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:16:57.369+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:17:01.541+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:01.540+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:17:01.560+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:01.560+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:17:01.561+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:01.561+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:17:01.563+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:01.563+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:17:01.569+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:01.567+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:17:01.569+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:17:01.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.211 seconds
[2024-03-25T16:17:31.746+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:17:31.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:17:31.749+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:31.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:17:35.858+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:35.858+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:17:35.869+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:35.869+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:17:35.870+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:35.870+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:17:35.872+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:35.871+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:17:35.876+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:17:35.875+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:17:35.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:17:35.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.139 seconds
[2024-03-25T16:18:06.091+0000] {processor.py:161} INFO - Started process (PID=462) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:18:06.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:18:06.094+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:06.093+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:18:10.270+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:10.270+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:18:10.284+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:10.284+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:18:10.285+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:10.285+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:18:10.289+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:10.289+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:18:10.296+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:10.293+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:18:10.297+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:18:10.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.217 seconds
[2024-03-25T16:18:40.459+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:18:40.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:18:40.462+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:40.461+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:18:44.565+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:44.564+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:18:44.586+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:44.586+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:18:44.587+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:44.587+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:18:44.589+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:44.589+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:18:44.594+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:18:44.592+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:18:44.595+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:18:44.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.146 seconds
[2024-03-25T16:19:14.690+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:19:14.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:19:14.693+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:14.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:19:18.867+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:18.867+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:19:18.878+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:18.878+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:19:18.879+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:18.879+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:19:18.880+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:18.880+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:19:18.884+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:18.883+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:19:18.885+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:19:18.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.202 seconds
[2024-03-25T16:19:49.136+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:19:49.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:19:49.138+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:49.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:19:53.394+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:53.393+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:19:53.406+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:53.406+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:19:53.407+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:53.407+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:19:53.408+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:53.408+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:19:53.413+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:19:53.411+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:19:53.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:19:53.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.285 seconds
[2024-03-25T16:20:23.457+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:20:23.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:20:23.459+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:20:23.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:20:27.654+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:20:27.653+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:20:27.668+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:20:27.668+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:20:27.669+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:20:27.669+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:20:27.671+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:20:27.671+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:20:27.677+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:20:27.675+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:20:27.677+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:20:27.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.229 seconds
[2024-03-25T16:20:57.736+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:20:57.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:20:57.739+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:20:57.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:21:02.025+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:02.024+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:21:02.045+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:02.044+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:21:02.046+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:02.046+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:21:02.049+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:02.049+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:21:02.055+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:02.053+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:21:02.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:21:02.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.330 seconds
[2024-03-25T16:21:33.042+0000] {processor.py:161} INFO - Started process (PID=673) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:21:33.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:21:33.044+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:33.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:21:37.200+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:37.199+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:21:37.218+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:37.218+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:21:37.220+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:37.220+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:21:37.221+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:37.221+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:21:37.227+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:21:37.225+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:21:37.228+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:21:37.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.197 seconds
[2024-03-25T16:22:07.376+0000] {processor.py:161} INFO - Started process (PID=718) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:22:07.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:22:07.377+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:07.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:22:11.579+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:11.579+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:22:11.590+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:11.590+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:22:11.592+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:11.592+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:22:11.593+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:11.593+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:22:11.598+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:11.596+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:22:11.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:22:11.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.229 seconds
[2024-03-25T16:22:42.567+0000] {processor.py:161} INFO - Started process (PID=753) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:22:42.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:22:42.569+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:42.569+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:22:46.768+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:46.768+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:22:46.789+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:46.788+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:22:46.790+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:46.790+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:22:46.792+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:46.792+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:22:46.797+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:22:46.795+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:22:46.798+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:22:46.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.239 seconds
[2024-03-25T16:23:16.886+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:23:16.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:23:16.888+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:16.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:23:21.002+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:21.001+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:23:21.018+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:21.018+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:23:21.019+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:21.019+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:23:21.020+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:21.020+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:23:21.024+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:21.023+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:23:21.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:23:21.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.147 seconds
[2024-03-25T16:23:51.258+0000] {processor.py:161} INFO - Started process (PID=823) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:23:51.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:23:51.262+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:51.261+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:23:55.428+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:55.426+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:23:55.451+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:55.451+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:23:55.453+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:55.453+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:23:55.455+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:55.455+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:23:55.461+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:23:55.459+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:23:55.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:23:55.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.213 seconds
[2024-03-25T16:24:25.535+0000] {processor.py:161} INFO - Started process (PID=858) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:24:25.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:24:25.539+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:24:25.538+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:24:29.650+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:24:29.649+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:24:29.674+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:24:29.674+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:24:29.676+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:24:29.676+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:24:29.678+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:24:29.677+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:24:29.684+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:24:29.682+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:24:29.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:24:29.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.161 seconds
[2024-03-25T16:24:59.837+0000] {processor.py:161} INFO - Started process (PID=893) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:24:59.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:24:59.841+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:24:59.840+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:25:04.063+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:04.062+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:25:04.078+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:04.077+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:25:04.079+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:04.079+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:25:04.080+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:04.080+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:25:04.085+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:04.084+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:25:04.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:25:04.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.259 seconds
[2024-03-25T16:25:35.108+0000] {processor.py:161} INFO - Started process (PID=931) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:25:35.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:25:35.110+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:35.109+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:25:39.266+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:39.265+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:25:39.277+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:39.277+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:25:39.278+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:39.278+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:25:39.279+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:39.279+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:25:39.284+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:25:39.282+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:25:39.285+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:25:39.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.184 seconds
[2024-03-25T16:26:09.426+0000] {processor.py:161} INFO - Started process (PID=967) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:26:09.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:26:09.428+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:09.427+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:26:13.685+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:13.684+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:26:13.696+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:13.696+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:26:13.697+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:13.697+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:26:13.698+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:13.698+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:26:13.702+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:13.700+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:26:13.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:26:13.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.286 seconds
[2024-03-25T16:26:43.787+0000] {processor.py:161} INFO - Started process (PID=1003) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:26:43.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:26:43.791+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:43.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:26:47.902+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:47.900+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:26:47.923+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:47.923+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:26:47.925+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:47.925+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:26:47.927+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:47.927+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:26:47.933+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:26:47.931+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:26:47.934+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:26:47.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.157 seconds
[2024-03-25T16:27:18.109+0000] {processor.py:161} INFO - Started process (PID=1038) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:27:18.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:27:18.112+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:18.111+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:27:22.162+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:22.160+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:27:22.232+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:22.232+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:27:22.234+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:22.234+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:27:22.236+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:22.236+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:27:22.244+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:22.242+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:27:22.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:27:22.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.148 seconds
[2024-03-25T16:27:52.434+0000] {processor.py:161} INFO - Started process (PID=1082) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:27:52.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:27:52.436+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:52.436+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:27:56.598+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:56.596+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:27:56.619+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:56.619+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:27:56.621+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:56.621+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:27:56.623+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:56.623+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:27:56.629+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:27:56.627+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:27:56.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:27:56.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.204 seconds
[2024-03-25T16:28:26.679+0000] {processor.py:161} INFO - Started process (PID=1117) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:28:26.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:28:26.681+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:28:26.681+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:28:31.051+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:28:31.050+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:28:31.073+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:28:31.072+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:28:31.075+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:28:31.075+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:28:31.077+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:28:31.077+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:28:31.084+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:28:31.082+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:28:31.085+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:28:31.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.416 seconds
[2024-03-25T16:29:01.993+0000] {processor.py:161} INFO - Started process (PID=1152) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:29:01.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:29:01.995+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:01.995+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:29:06.277+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:06.274+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:29:06.303+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:06.303+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:29:06.305+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:06.305+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:29:06.307+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:06.307+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:29:06.314+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:06.311+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:29:06.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:29:06.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.333 seconds
[2024-03-25T16:29:37.341+0000] {processor.py:161} INFO - Started process (PID=1190) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:29:37.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:29:37.343+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:37.343+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:29:41.430+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:41.428+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:29:41.452+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:41.452+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:29:41.454+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:41.454+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:29:41.456+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:41.456+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:29:41.464+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:29:41.461+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:29:41.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:29:41.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.134 seconds
[2024-03-25T16:30:11.780+0000] {processor.py:161} INFO - Started process (PID=1227) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:30:11.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:30:11.784+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:11.783+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:30:16.087+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:16.086+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:30:16.100+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:16.100+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:30:16.101+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:16.101+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:30:16.104+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:16.103+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:30:16.111+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:16.106+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:30:16.112+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:30:16.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.344 seconds
[2024-03-25T16:30:47.075+0000] {processor.py:161} INFO - Started process (PID=1262) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:30:47.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:30:47.078+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:47.078+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:30:51.256+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:51.255+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:30:51.274+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:51.273+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:30:51.275+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:51.275+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:30:51.277+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:51.277+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:30:51.283+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:30:51.281+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:30:51.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:30:51.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.221 seconds
[2024-03-25T16:31:21.392+0000] {processor.py:161} INFO - Started process (PID=1297) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:31:21.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:31:21.395+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:21.394+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:31:25.501+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:25.500+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:31:25.512+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:25.512+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:31:25.513+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:25.513+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:31:25.514+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:25.514+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:31:25.518+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:25.517+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:31:25.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:31:25.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.134 seconds
[2024-03-25T16:31:55.656+0000] {processor.py:161} INFO - Started process (PID=1332) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:31:55.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:31:55.661+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:55.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:31:59.778+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:59.777+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:31:59.790+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:59.790+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:31:59.792+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:59.791+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:31:59.793+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:59.793+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:31:59.797+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:31:59.796+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:31:59.798+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:31:59.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.151 seconds
[2024-03-25T16:36:41.026+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:36:41.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:36:41.028+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:36:41.027+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:36:45.565+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:36:45.565+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:36:45.579+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:36:45.578+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:36:45.580+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:36:45.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.562 seconds
[2024-03-25T16:37:16.381+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:37:16.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:37:16.383+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:16.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:37:20.421+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:20.420+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:37:20.432+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:20.431+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:37:20.433+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:37:20.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.059 seconds
[2024-03-25T16:37:50.590+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:37:50.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:37:50.592+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:50.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:37:54.696+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:54.695+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:37:54.713+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:54.713+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:37:54.716+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:54.715+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:37:54.717+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:54.717+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:37:54.726+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:37:54.724+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:37:54.726+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:37:54.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.145 seconds
[2024-03-25T16:38:24.899+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:38:24.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:38:24.901+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:38:24.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:38:29.067+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:38:29.066+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:38:29.088+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:38:29.087+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:38:29.089+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:38:29.089+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:38:29.091+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:38:29.091+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:38:29.097+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:38:29.095+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:38:29.097+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:38:29.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.207 seconds
[2024-03-25T16:38:59.205+0000] {processor.py:161} INFO - Started process (PID=310) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:38:59.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:38:59.210+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:38:59.209+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:39:03.455+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:03.455+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:39:03.468+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:03.468+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:39:03.469+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:03.469+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:39:03.470+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:03.470+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:39:03.475+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:03.473+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:39:03.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:39:03.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.280 seconds
[2024-03-25T16:39:34.394+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:39:34.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:39:34.396+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:34.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:39:38.607+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:38.606+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:39:38.621+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:38.621+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:39:38.623+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:38.623+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:39:38.625+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:38.625+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:39:38.631+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:39:38.629+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:39:38.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:39:38.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.246 seconds
[2024-03-25T16:40:08.718+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:40:08.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:40:08.722+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:40:08.721+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:40:12.915+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:40:12.914+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:40:12.928+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:40:12.928+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:40:12.929+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:40:12.929+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:40:12.931+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:40:12.931+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:40:12.936+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:40:12.934+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 22, in build_exec_pipeline_sales_data
    mysql_client = create_engine("mysql+mysqldb" + conn_hook.get_uri()[5:])
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:40:12.937+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:40:12.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.232 seconds
[2024-03-25T16:42:04.491+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:42:04.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:42:04.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:42:04.493+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:42:09.023+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:42:09.023+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:42:09.036+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:42:09.034+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:42:09.036+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:42:09.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.554 seconds
[2024-03-25T16:42:39.867+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:42:39.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:42:39.871+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:42:39.871+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:42:44.402+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:42:44.400+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:42:44.421+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:42:44.418+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:42:44.421+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:42:44.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.566 seconds
[2024-03-25T16:43:15.129+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:43:15.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:43:15.131+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:15.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:43:19.307+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:19.305+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:43:19.331+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:19.331+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:43:19.334+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:19.333+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:43:19.336+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:19.336+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:43:19.347+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:19.344+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:43:19.347+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:43:19.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.228 seconds
[2024-03-25T16:43:49.450+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:43:49.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:43:49.455+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:49.454+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:43:53.696+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:53.695+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:43:53.720+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:53.720+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:43:53.722+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:53.722+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:43:53.724+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:53.724+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:43:53.732+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:43:53.729+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:43:53.732+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:43:53.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.298 seconds
[2024-03-25T16:44:23.786+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:44:23.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:44:23.788+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:44:23.788+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:44:28.023+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:44:28.020+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:44:28.050+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:44:28.050+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:44:28.052+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:44:28.052+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:44:28.054+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:44:28.054+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:44:28.061+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:44:28.059+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:44:28.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:44:28.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.286 seconds
[2024-03-25T16:44:58.131+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:44:58.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:44:58.132+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:44:58.132+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:45:02.375+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:02.375+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:45:02.387+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:02.387+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:45:02.388+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:02.388+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:45:02.389+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:02.389+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:45:02.393+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:02.391+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:45:02.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:45:02.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.271 seconds
[2024-03-25T16:45:33.394+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:45:33.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:45:33.401+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:33.400+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:45:37.586+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:37.586+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:45:37.600+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:37.600+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:45:37.601+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:37.601+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:45:37.603+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:37.603+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:45:37.609+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:45:37.606+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:45:37.609+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:45:37.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.226 seconds
[2024-03-25T16:46:07.698+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:46:07.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:46:07.700+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:07.700+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:46:12.068+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:12.066+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:46:12.092+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:12.091+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:46:12.094+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:12.094+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:46:12.096+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:12.096+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:46:12.104+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:12.102+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:46:12.105+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:46:12.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.417 seconds
[2024-03-25T16:46:43.030+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:46:43.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:46:43.032+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:43.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:46:47.181+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:47.181+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:46:47.194+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:47.194+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:46:47.195+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:47.195+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:46:47.196+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:47.196+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:46:47.201+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:46:47.199+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:46:47.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:46:47.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.181 seconds
[2024-03-25T16:47:17.399+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:47:17.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:47:17.401+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:17.401+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:47:21.702+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:21.700+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:47:21.721+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:21.721+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:47:21.723+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:21.723+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:47:21.725+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:21.725+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:47:21.732+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:21.729+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:47:21.732+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:47:21.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.343 seconds
[2024-03-25T16:47:52.711+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:47:52.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:47:52.715+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:52.714+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:47:56.894+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:56.894+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:47:56.907+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:56.907+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:47:56.909+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:56.908+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:47:56.910+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:56.910+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:47:56.915+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:47:56.913+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:47:56.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:47:56.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.214 seconds
[2024-03-25T16:48:27.047+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:48:27.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:48:27.051+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:48:27.050+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:48:31.245+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:48:31.244+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:48:31.256+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:48:31.256+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:48:31.257+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:48:31.257+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:48:31.259+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:48:31.258+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:48:31.263+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:48:31.261+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:48:31.263+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:48:31.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.226 seconds
[2024-03-25T16:49:01.361+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:49:01.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:49:01.364+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:01.363+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:49:05.650+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:05.648+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:49:05.675+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:05.675+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:49:05.678+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:05.677+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:49:05.679+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:05.679+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:49:05.687+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:05.684+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:49:05.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:49:05.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.338 seconds
[2024-03-25T16:49:36.695+0000] {processor.py:161} INFO - Started process (PID=638) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:49:36.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:49:36.709+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:36.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:49:40.967+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:40.967+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:49:40.980+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:40.980+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:49:40.981+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:40.981+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:49:40.983+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:40.983+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:49:40.987+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:49:40.985+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:49:40.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:49:40.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.304 seconds
[2024-03-25T16:50:11.139+0000] {processor.py:161} INFO - Started process (PID=686) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:50:11.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:50:11.141+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:11.140+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:50:15.347+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:15.346+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:50:15.360+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:15.359+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:50:15.361+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:15.361+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:50:15.362+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:15.362+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:50:15.367+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:15.365+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:50:15.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:50:15.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.236 seconds
[2024-03-25T16:50:45.443+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:50:45.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:50:45.446+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:45.445+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:50:49.599+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:49.597+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:50:49.622+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:49.622+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:50:49.624+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:49.624+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:50:49.626+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:49.626+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:50:49.632+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:50:49.630+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:50:49.633+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:50:49.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.199 seconds
[2024-03-25T16:51:19.715+0000] {processor.py:161} INFO - Started process (PID=756) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:51:19.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:51:19.717+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:19.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:51:23.975+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:23.974+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:51:23.996+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:23.996+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:51:23.998+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:23.997+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:51:23.999+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:23.999+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:51:24.005+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:24.003+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:51:24.006+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:51:24.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.299 seconds
[2024-03-25T16:51:54.096+0000] {processor.py:161} INFO - Started process (PID=791) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:51:54.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:51:54.100+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:54.099+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:51:58.439+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:58.437+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:51:58.457+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:58.456+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:51:58.458+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:58.458+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:51:58.459+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:58.459+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:51:58.463+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:51:58.462+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:51:58.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:51:58.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.378 seconds
[2024-03-25T16:52:29.388+0000] {processor.py:161} INFO - Started process (PID=826) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:52:29.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:52:29.392+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:52:29.391+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:52:33.625+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:52:33.624+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:52:33.639+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:52:33.639+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:52:33.641+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:52:33.641+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:52:33.643+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:52:33.643+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:52:33.650+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:52:33.647+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:52:33.650+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:52:33.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.275 seconds
[2024-03-25T16:53:04.653+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:53:04.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:53:04.655+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:04.654+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:53:09.513+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:09.512+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:53:09.537+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:09.537+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:53:09.538+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:09.538+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:53:09.540+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:09.540+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:53:09.546+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:09.544+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:53:09.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:53:09.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.903 seconds
[2024-03-25T16:53:39.862+0000] {processor.py:161} INFO - Started process (PID=896) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:53:39.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:53:39.866+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:39.865+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:53:44.026+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:44.025+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:53:44.036+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:44.036+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:53:44.038+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:44.038+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:53:44.039+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:44.039+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:53:44.044+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:53:44.042+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:53:44.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:53:44.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.193 seconds
[2024-03-25T16:54:14.289+0000] {processor.py:161} INFO - Started process (PID=936) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:54:14.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:54:14.291+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:14.291+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:54:18.443+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:18.442+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:54:18.455+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:18.455+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:54:18.456+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:18.456+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:54:18.457+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:18.457+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:54:18.462+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:18.460+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:54:18.463+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:54:18.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.184 seconds
[2024-03-25T16:54:48.603+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:54:48.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:54:48.605+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:48.605+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:54:52.787+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:52.786+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:54:52.807+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:52.807+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:54:52.809+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:52.809+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:54:52.811+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:52.810+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:54:52.816+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:54:52.814+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:54:52.816+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:54:52.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.221 seconds
[2024-03-25T16:55:22.916+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:55:22.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:55:22.919+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:55:22.918+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:55:26.984+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:55:26.983+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:55:26.999+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:55:26.999+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:55:27.001+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:55:27.000+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:55:27.003+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:55:27.003+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:55:27.009+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:55:27.006+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:55:27.009+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:55:27.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.102 seconds
[2024-03-25T16:55:57.212+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:55:57.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:55:57.215+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:55:57.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:56:01.496+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:01.494+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:56:01.514+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:01.514+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:56:01.516+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:01.516+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:56:01.517+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:01.517+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:56:01.523+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:01.521+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:56:01.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:56:01.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.320 seconds
[2024-03-25T16:56:32.453+0000] {processor.py:161} INFO - Started process (PID=1085) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:56:32.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:56:32.455+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:32.454+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:56:36.687+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:36.685+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:56:36.702+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:36.702+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:56:36.703+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:36.703+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:56:36.705+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:36.705+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:56:36.709+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:56:36.708+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:56:36.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:56:36.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.264 seconds
[2024-03-25T16:57:06.790+0000] {processor.py:161} INFO - Started process (PID=1120) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:57:06.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:57:06.791+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:06.791+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:57:11.031+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:11.030+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:57:11.057+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:11.057+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:57:11.059+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:11.059+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:57:11.061+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:11.061+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:57:11.067+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:11.065+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:57:11.068+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:57:11.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.288 seconds
[2024-03-25T16:57:49.544+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:57:49.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:57:49.545+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:49.545+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:57:54.140+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:54.140+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:57:54.155+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:57:54.153+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:57:54.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:57:54.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.620 seconds
[2024-03-25T16:58:24.930+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:58:24.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:58:24.932+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:58:24.932+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:58:28.897+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:58:28.897+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:58:28.909+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:58:28.908+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T16:58:28.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:58:28.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 3.989 seconds
[2024-03-25T16:58:59.155+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:58:59.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:58:59.158+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:58:59.157+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:59:03.229+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:03.229+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:59:03.240+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:03.240+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:59:03.241+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:03.241+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:59:03.242+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:03.242+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:59:03.249+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:03.248+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:59:03.250+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:59:03.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.103 seconds
[2024-03-25T16:59:33.414+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:59:33.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T16:59:33.416+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:33.415+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:59:37.652+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:37.651+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:59:37.675+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:37.675+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:59:37.676+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:37.676+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T16:59:37.679+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:37.678+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T16:59:37.685+0000] {logging_mixin.py:188} INFO - [2024-03-25T16:59:37.682+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T16:59:37.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T16:59:37.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.280 seconds
[2024-03-25T17:00:07.752+0000] {processor.py:161} INFO - Started process (PID=310) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:00:07.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:00:07.755+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:07.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:00:11.857+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:11.856+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:00:11.879+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:11.879+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:00:11.881+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:11.880+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:00:11.883+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:11.882+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:00:11.889+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:11.886+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:00:11.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:00:11.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.148 seconds
[2024-03-25T17:00:42.015+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:00:42.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:00:42.017+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:42.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:00:46.241+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:46.240+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:00:46.257+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:46.256+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:00:46.258+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:46.258+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:00:46.260+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:46.260+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:00:46.265+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:00:46.263+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:00:46.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:00:46.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.259 seconds
[2024-03-25T17:01:16.336+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:01:16.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:01:16.338+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:16.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:01:20.565+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:20.564+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:01:20.588+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:20.588+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:01:20.590+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:20.590+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:01:20.592+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:20.591+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:01:20.598+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:20.596+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:01:20.599+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:01:20.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.270 seconds
[2024-03-25T17:01:51.612+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:01:51.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:01:51.614+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:51.613+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:01:56.027+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:56.026+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:01:56.052+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:56.052+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:01:56.054+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:56.054+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:01:56.057+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:56.057+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:01:56.064+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:01:56.061+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:01:56.064+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:01:56.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.463 seconds
[2024-03-25T17:02:26.998+0000] {processor.py:161} INFO - Started process (PID=464) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:02:26.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:02:27.000+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:02:27.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:02:31.125+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:02:31.123+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:02:31.150+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:02:31.150+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:02:31.151+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:02:31.151+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:02:31.153+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:02:31.153+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:02:31.160+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:02:31.158+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:02:31.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:02:31.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.175 seconds
[2024-03-25T17:03:01.378+0000] {processor.py:161} INFO - Started process (PID=499) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:03:01.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:03:01.381+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:01.381+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:03:05.565+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:05.564+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:03:05.580+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:05.580+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:03:05.582+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:05.582+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:03:05.583+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:05.583+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:03:05.589+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:05.587+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:03:05.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:03:05.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.222 seconds
[2024-03-25T17:03:35.653+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:03:35.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:03:35.656+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:35.655+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:03:40.072+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:40.072+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:03:40.083+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:40.083+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:03:40.084+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:40.084+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:03:40.085+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:40.085+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:03:40.089+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:03:40.087+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:03:40.089+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:03:40.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.445 seconds
[2024-03-25T17:04:11.006+0000] {processor.py:161} INFO - Started process (PID=569) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:04:11.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:04:11.008+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:11.008+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:04:15.179+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:15.177+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:04:15.201+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:15.201+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:04:15.203+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:15.203+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:04:15.205+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:15.204+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:04:15.210+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:15.208+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:04:15.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:04:15.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.215 seconds
[2024-03-25T17:04:45.328+0000] {processor.py:161} INFO - Started process (PID=604) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:04:45.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:04:45.329+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:45.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:04:49.471+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:49.470+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:04:49.486+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:49.485+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:04:49.487+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:49.487+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:04:49.488+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:49.488+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:04:49.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:04:49.491+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:04:49.494+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:04:49.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.173 seconds
[2024-03-25T17:05:19.628+0000] {processor.py:161} INFO - Started process (PID=639) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:05:19.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:05:19.631+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:19.630+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:05:23.950+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:23.949+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:05:23.967+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:23.967+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:05:23.968+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:23.968+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:05:23.970+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:23.970+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:05:23.975+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:23.974+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:05:23.976+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:05:23.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.357 seconds
[2024-03-25T17:05:54.965+0000] {processor.py:161} INFO - Started process (PID=687) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:05:54.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:05:54.968+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:54.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:05:59.194+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:59.193+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:05:59.218+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:59.218+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:05:59.220+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:59.220+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:05:59.222+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:59.222+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:05:59.230+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:05:59.227+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:05:59.230+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:05:59.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.277 seconds
[2024-03-25T17:06:29.307+0000] {processor.py:161} INFO - Started process (PID=722) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:06:29.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:06:29.310+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:06:29.309+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:06:33.497+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:06:33.496+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:06:33.511+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:06:33.511+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:06:33.512+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:06:33.512+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:06:33.514+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:06:33.514+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:06:33.519+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:06:33.517+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:06:33.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:06:33.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.220 seconds
[2024-03-25T17:07:03.574+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:07:03.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:07:03.576+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:03.575+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:07:07.742+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:07.741+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:07:07.760+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:07.760+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:07:07.762+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:07.761+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:07:07.763+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:07.763+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:07:07.769+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:07.766+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:07:07.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:07:07.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.203 seconds
[2024-03-25T17:07:37.948+0000] {processor.py:161} INFO - Started process (PID=792) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:07:37.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:07:37.950+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:37.950+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:07:42.337+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:42.336+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:07:42.363+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:42.362+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:07:42.367+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:42.367+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:07:42.369+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:42.369+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:07:42.375+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:07:42.373+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:07:42.375+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:07:42.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.436 seconds
[2024-03-25T17:08:13.229+0000] {processor.py:161} INFO - Started process (PID=827) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:08:13.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:08:13.230+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:13.230+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:08:17.422+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:17.421+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:08:17.441+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:17.441+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:08:17.442+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:17.442+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:08:17.445+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:17.445+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:08:17.450+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:17.448+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:08:17.451+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:08:17.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.230 seconds
[2024-03-25T17:08:47.523+0000] {processor.py:161} INFO - Started process (PID=862) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:08:47.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:08:47.526+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:47.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:08:51.635+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:51.635+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:08:51.647+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:51.647+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:08:51.648+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:51.648+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:08:51.649+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:51.649+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:08:51.653+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:08:51.652+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:08:51.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:08:51.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.140 seconds
[2024-03-25T17:09:21.850+0000] {processor.py:161} INFO - Started process (PID=897) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:09:21.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:09:21.854+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:09:21.853+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:09:25.978+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:09:25.977+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:09:25.987+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:09:25.987+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:09:25.988+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:09:25.988+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:09:25.989+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:09:25.989+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:09:25.994+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:09:25.992+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:09:25.994+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:09:25.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.153 seconds
[2024-03-25T17:09:56.174+0000] {processor.py:161} INFO - Started process (PID=935) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:09:56.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:09:56.176+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:09:56.176+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:10:00.387+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:00.386+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:10:00.405+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:00.405+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:10:00.406+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:00.406+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:10:00.408+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:00.408+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:10:00.414+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:00.412+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:10:00.415+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:10:00.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.249 seconds
[2024-03-25T17:10:30.495+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:10:30.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:10:30.497+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:30.496+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:10:34.644+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:34.644+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:10:34.656+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:34.656+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:10:34.657+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:34.657+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:10:34.658+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:34.658+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:10:34.662+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:10:34.660+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:10:34.662+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:10:34.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.176 seconds
[2024-03-25T17:11:04.708+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:11:04.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:11:04.710+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:04.710+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:11:09.047+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:09.046+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:11:09.073+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:09.073+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:11:09.075+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:09.075+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:11:09.078+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:09.078+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:11:09.085+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:09.083+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:11:09.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:11:09.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.388 seconds
[2024-03-25T17:11:40.006+0000] {processor.py:161} INFO - Started process (PID=1050) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:11:40.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:11:40.009+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:40.008+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:11:44.319+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:44.318+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:11:44.340+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:44.340+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:11:44.342+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:44.341+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:11:44.343+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:44.343+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:11:44.349+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:11:44.347+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:11:44.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:11:44.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.352 seconds
[2024-03-25T17:12:15.299+0000] {processor.py:161} INFO - Started process (PID=1085) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:12:15.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:12:15.302+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:15.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:12:19.463+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:19.462+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:12:19.483+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:19.482+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:12:19.484+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:19.484+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:12:19.486+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:19.486+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:12:19.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:19.490+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:12:19.493+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:12:19.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.205 seconds
[2024-03-25T17:12:49.557+0000] {processor.py:161} INFO - Started process (PID=1120) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:12:49.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:12:49.560+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:49.559+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:12:53.879+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:53.878+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:12:53.890+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:53.890+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:12:53.891+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:53.891+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:12:53.892+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:53.892+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:12:53.896+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:12:53.895+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:12:53.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:12:53.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.349 seconds
[2024-03-25T17:13:24.843+0000] {processor.py:161} INFO - Started process (PID=1155) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:13:24.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:13:24.846+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:13:24.845+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:13:29.071+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:13:29.071+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:13:29.083+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:13:29.082+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:13:29.084+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:13:29.084+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:13:29.085+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:13:29.085+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:13:29.090+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:13:29.088+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:13:29.090+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:13:29.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.255 seconds
[2024-03-25T17:13:59.179+0000] {processor.py:161} INFO - Started process (PID=1195) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:13:59.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:13:59.182+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:13:59.181+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:14:03.505+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:03.504+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:14:03.525+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:03.525+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:14:03.526+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:03.526+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:14:03.529+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:03.529+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:14:03.535+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:03.532+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:14:03.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:14:03.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.368 seconds
[2024-03-25T17:14:34.469+0000] {processor.py:161} INFO - Started process (PID=1230) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:14:34.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:14:34.471+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:34.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:14:38.661+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:38.658+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:14:38.687+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:38.687+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:14:38.690+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:38.689+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:14:38.691+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:38.691+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:14:38.699+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:14:38.696+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:14:38.699+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:14:38.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.241 seconds
[2024-03-25T17:15:08.781+0000] {processor.py:161} INFO - Started process (PID=1273) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:15:08.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:15:08.782+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:08.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:15:13.048+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:13.046+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:15:13.073+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:13.073+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:15:13.075+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:13.075+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:15:13.077+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:13.077+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:15:13.083+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:13.081+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:15:13.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:15:13.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.312 seconds
[2024-03-25T17:15:43.142+0000] {processor.py:161} INFO - Started process (PID=1308) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:15:43.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:15:43.144+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:43.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:15:47.461+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:47.460+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:15:47.482+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:47.481+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:15:47.483+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:47.483+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:15:47.485+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:47.485+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:15:47.490+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:15:47.488+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:15:47.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:15:47.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.360 seconds
[2024-03-25T17:16:18.406+0000] {processor.py:161} INFO - Started process (PID=1343) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:16:18.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:16:18.410+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:18.409+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:16:22.647+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:22.645+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:16:22.672+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:22.672+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:16:22.674+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:22.674+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:16:22.676+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:22.676+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:16:22.683+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:22.680+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:16:22.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:16:22.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.289 seconds
[2024-03-25T17:16:53.625+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:16:53.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:16:53.627+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:53.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:16:57.860+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:57.859+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:16:57.881+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:57.881+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:16:57.882+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:57.882+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:16:57.884+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:57.884+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:16:57.890+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:16:57.888+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:16:57.890+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:16:57.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.274 seconds
[2024-03-25T17:17:27.964+0000] {processor.py:161} INFO - Started process (PID=1414) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:17:27.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:17:27.967+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:17:27.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:17:32.111+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:17:32.111+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:17:32.124+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:17:32.124+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:17:32.125+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:17:32.125+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:17:32.127+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:17:32.127+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:17:32.131+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:17:32.130+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:17:32.132+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:17:32.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.176 seconds
[2024-03-25T17:18:02.338+0000] {processor.py:161} INFO - Started process (PID=1454) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:18:02.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:18:02.340+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:02.340+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:18:06.531+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:06.531+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:18:06.543+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:06.543+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:18:06.545+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:06.545+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:18:06.546+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:06.546+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:18:06.550+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:06.549+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:18:06.551+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:18:06.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.222 seconds
[2024-03-25T17:18:36.670+0000] {processor.py:161} INFO - Started process (PID=1489) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:18:36.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:18:36.671+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:36.671+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:18:40.934+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:40.933+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:18:40.944+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:40.944+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:18:40.945+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:40.945+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:18:40.946+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:40.946+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:18:40.949+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:18:40.948+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:18:40.950+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:18:40.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.286 seconds
[2024-03-25T17:19:11.062+0000] {processor.py:161} INFO - Started process (PID=1524) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:19:11.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:19:11.065+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:11.065+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:19:15.259+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:15.258+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:19:15.280+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:15.280+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:19:15.282+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:15.282+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:19:15.284+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:15.284+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:19:15.290+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:15.288+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:19:15.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:19:15.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.241 seconds
[2024-03-25T17:19:45.334+0000] {processor.py:161} INFO - Started process (PID=1566) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:19:45.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:19:45.336+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:45.336+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:19:49.472+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:49.471+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:19:49.484+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:49.483+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:19:49.485+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:49.484+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:19:49.486+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:49.486+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:19:49.490+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:19:49.488+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:19:49.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:19:49.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.163 seconds
[2024-03-25T17:20:19.633+0000] {processor.py:161} INFO - Started process (PID=1602) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:20:19.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:20:19.634+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:19.634+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:20:23.808+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:23.807+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:20:23.943+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:23.943+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:20:23.944+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:23.944+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:20:23.945+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:23.945+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:20:23.949+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:23.947+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:20:23.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:20:23.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.322 seconds
[2024-03-25T17:20:54.938+0000] {processor.py:161} INFO - Started process (PID=1637) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:20:54.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:20:54.942+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:54.942+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:20:59.189+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:59.187+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:20:59.213+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:59.213+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:20:59.215+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:59.215+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:20:59.217+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:59.217+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:20:59.224+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:20:59.222+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:20:59.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:20:59.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.298 seconds
[2024-03-25T17:21:30.264+0000] {processor.py:161} INFO - Started process (PID=1672) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:21:30.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:21:30.267+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:21:30.266+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:21:34.405+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:21:34.404+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:21:34.416+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:21:34.416+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:21:34.417+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:21:34.417+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:21:34.418+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:21:34.418+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:21:34.422+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:21:34.420+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:21:34.422+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:21:34.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.169 seconds
[2024-03-25T17:22:04.603+0000] {processor.py:161} INFO - Started process (PID=1712) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:22:04.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:22:04.607+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:04.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:22:08.833+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:08.831+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:22:08.854+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:08.854+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:22:08.856+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:08.856+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:22:08.858+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:08.858+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:22:08.864+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:08.862+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:22:08.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:22:08.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.271 seconds
[2024-03-25T17:22:38.934+0000] {processor.py:161} INFO - Started process (PID=1747) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:22:38.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:22:38.937+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:38.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:22:43.163+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:43.162+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:22:43.174+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:43.174+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:22:43.175+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:43.174+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:22:43.176+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:43.176+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:22:43.180+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:22:43.178+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:22:43.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:22:43.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.254 seconds
[2024-03-25T17:23:13.222+0000] {processor.py:161} INFO - Started process (PID=1782) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:23:13.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:23:13.224+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:13.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:23:17.355+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:17.354+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:23:17.483+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:17.483+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:23:17.484+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:17.484+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:23:17.485+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:17.485+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:23:17.489+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:17.487+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:23:17.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:23:17.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.273 seconds
[2024-03-25T17:23:47.571+0000] {processor.py:161} INFO - Started process (PID=1817) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:23:47.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:23:47.574+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:47.573+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:23:51.841+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:51.841+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:23:51.856+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:51.856+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:23:51.857+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:51.857+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:23:51.859+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:51.859+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:23:51.864+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:23:51.862+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:23:51.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:23:51.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.301 seconds
[2024-03-25T17:24:21.928+0000] {processor.py:161} INFO - Started process (PID=1852) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:24:21.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:24:21.931+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:24:21.931+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:24:26.128+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:24:26.126+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:24:26.154+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:24:26.154+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:24:26.156+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:24:26.156+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:24:26.158+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:24:26.158+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:24:26.163+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:24:26.161+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:24:26.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:24:26.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.246 seconds
[2024-03-25T17:24:56.229+0000] {processor.py:161} INFO - Started process (PID=1896) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:24:56.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:24:56.231+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:24:56.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:25:00.312+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:00.310+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:25:00.333+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:00.333+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:25:00.335+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:00.335+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:25:00.337+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:00.337+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:25:00.343+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:00.341+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:25:00.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:25:00.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.122 seconds
[2024-03-25T17:25:30.492+0000] {processor.py:161} INFO - Started process (PID=1931) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:25:30.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:25:30.495+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:30.494+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:25:34.690+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:34.689+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:25:34.701+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:34.701+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:25:34.702+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:34.702+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:25:34.703+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:34.703+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:25:34.708+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:25:34.706+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:25:34.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:25:34.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.226 seconds
[2024-03-25T17:26:04.898+0000] {processor.py:161} INFO - Started process (PID=1970) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:26:04.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:26:04.900+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:04.899+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:26:09.152+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:09.150+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:26:09.289+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:09.289+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:26:09.290+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:09.290+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:26:09.291+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:09.291+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:26:09.295+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:09.293+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:26:09.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:26:09.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.403 seconds
[2024-03-25T17:26:39.372+0000] {processor.py:161} INFO - Started process (PID=2007) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:26:39.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:26:39.376+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:39.376+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:26:43.675+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:43.673+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:26:43.701+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:43.701+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:26:43.703+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:43.703+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:26:43.706+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:43.706+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:26:43.712+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:26:43.710+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:26:43.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:26:43.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.352 seconds
[2024-03-25T17:27:14.686+0000] {processor.py:161} INFO - Started process (PID=2042) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:27:14.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:27:14.689+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:14.688+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:27:19.072+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:19.071+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:27:19.101+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:19.101+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:27:19.103+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:19.103+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:27:19.105+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:19.105+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:27:19.112+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:19.109+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:27:19.112+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:27:19.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.439 seconds
[2024-03-25T17:27:49.975+0000] {processor.py:161} INFO - Started process (PID=2077) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:27:49.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:27:49.977+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:49.977+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:27:54.627+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:54.626+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:27:54.640+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:54.640+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:27:54.641+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:54.641+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:27:54.643+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:54.643+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:27:54.647+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:27:54.645+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:27:54.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:27:54.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.680 seconds
[2024-03-25T17:28:25.250+0000] {processor.py:161} INFO - Started process (PID=2112) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:28:25.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:28:25.254+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:28:25.253+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:28:29.429+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:28:29.428+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:28:29.450+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:28:29.450+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:28:29.453+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:28:29.453+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:28:29.455+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:28:29.455+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:28:29.461+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:28:29.459+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:28:29.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:28:29.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.223 seconds
[2024-03-25T17:28:59.530+0000] {processor.py:161} INFO - Started process (PID=2147) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:28:59.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:28:59.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:28:59.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:29:03.635+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:03.634+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:29:03.763+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:03.763+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:29:03.764+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:03.764+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:29:03.765+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:03.765+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:29:03.769+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:03.767+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:29:03.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:29:03.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.247 seconds
[2024-03-25T17:29:33.804+0000] {processor.py:161} INFO - Started process (PID=2190) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:29:33.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:29:33.806+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:33.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:29:38.162+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:38.161+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:29:38.173+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:38.173+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:29:38.174+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:38.174+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:29:38.175+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:38.175+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:29:38.179+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:29:38.178+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:29:38.179+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:29:38.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.381 seconds
[2024-03-25T17:30:09.120+0000] {processor.py:161} INFO - Started process (PID=2230) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:30:09.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:30:09.122+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:09.122+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:30:13.459+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:13.458+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:30:13.478+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:13.478+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:30:13.480+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:13.479+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:30:13.481+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:13.481+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:30:13.486+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:13.484+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:30:13.487+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:30:13.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.376 seconds
[2024-03-25T17:30:44.389+0000] {processor.py:161} INFO - Started process (PID=2265) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:30:44.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:30:44.391+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:44.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:30:48.655+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:48.653+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:30:48.674+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:48.674+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:30:48.676+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:48.676+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:30:48.677+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:48.677+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:30:48.684+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:30:48.682+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:30:48.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:30:48.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.304 seconds
[2024-03-25T17:31:18.742+0000] {processor.py:161} INFO - Started process (PID=2300) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:31:18.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:31:18.744+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:18.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:31:23.085+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:23.083+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:31:23.108+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:23.108+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:31:23.110+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:23.110+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:31:23.113+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:23.113+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:31:23.119+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:23.117+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:31:23.120+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:31:23.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.389 seconds
[2024-03-25T17:31:53.964+0000] {processor.py:161} INFO - Started process (PID=2335) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:31:53.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:31:53.966+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:53.966+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:31:58.248+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:58.247+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:31:58.355+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:58.354+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:31:58.355+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:58.355+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:31:58.356+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:58.356+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:31:58.360+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:31:58.359+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:31:58.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:31:58.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.404 seconds
[2024-03-25T17:32:29.310+0000] {processor.py:161} INFO - Started process (PID=2370) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:32:29.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:32:29.313+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:32:29.312+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:32:33.562+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:32:33.561+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:32:33.584+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:32:33.584+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:32:33.586+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:32:33.585+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:32:33.587+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:32:33.587+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:32:33.593+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:32:33.591+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:32:33.593+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:32:33.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.295 seconds
[2024-03-25T17:33:04.593+0000] {processor.py:161} INFO - Started process (PID=2413) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:33:04.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:33:04.595+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:04.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:33:08.726+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:08.725+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:33:08.734+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:08.734+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:33:08.735+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:08.735+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:33:08.736+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:08.736+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:33:08.740+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:08.738+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:33:08.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:33:08.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.153 seconds
[2024-03-25T17:33:38.956+0000] {processor.py:161} INFO - Started process (PID=2450) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:33:38.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:33:38.957+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:38.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:33:43.160+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:43.159+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:33:43.172+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:43.172+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:33:43.173+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:43.173+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:33:43.174+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:43.174+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:33:43.180+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:33:43.178+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:33:43.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:33:43.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.232 seconds
[2024-03-25T17:34:13.337+0000] {processor.py:161} INFO - Started process (PID=2486) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:34:13.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:34:13.339+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:13.338+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:34:17.567+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:17.566+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:34:17.578+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:17.578+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:34:17.579+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:17.579+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:34:17.580+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:17.580+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:34:17.585+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:17.583+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:34:17.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:34:17.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.255 seconds
[2024-03-25T17:34:47.661+0000] {processor.py:161} INFO - Started process (PID=2521) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:34:47.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:34:47.664+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:47.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:34:52.228+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:52.226+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:34:52.371+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:52.371+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:34:52.372+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:52.372+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:34:52.373+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:52.373+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:34:52.377+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:34:52.376+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:34:52.378+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:34:52.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.727 seconds
[2024-03-25T17:35:22.886+0000] {processor.py:161} INFO - Started process (PID=2556) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:35:22.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:35:22.887+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:35:22.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:35:27.255+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:35:27.253+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:35:27.269+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:35:27.268+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:35:27.269+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:35:27.269+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:35:27.270+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:35:27.270+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:35:27.274+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:35:27.273+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:35:27.275+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:35:27.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.395 seconds
[2024-03-25T17:35:58.265+0000] {processor.py:161} INFO - Started process (PID=2591) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:35:58.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:35:58.268+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:35:58.268+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:36:02.737+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:02.736+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:36:02.750+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:02.750+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:36:02.751+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:02.751+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:36:02.752+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:02.752+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:36:02.757+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:02.756+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:36:02.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:36:02.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.506 seconds
[2024-03-25T17:36:33.482+0000] {processor.py:161} INFO - Started process (PID=2626) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:36:33.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:36:33.484+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:33.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:36:38.080+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:38.079+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:36:38.102+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:38.102+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:36:38.104+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:38.104+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:36:38.106+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:38.106+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:36:38.113+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:36:38.110+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:36:38.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:36:38.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.641 seconds
[2024-03-25T17:37:08.772+0000] {processor.py:161} INFO - Started process (PID=2669) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:37:08.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:37:08.774+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:08.774+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:37:13.199+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:13.198+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:37:13.208+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:13.208+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:37:13.209+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:13.209+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:37:13.211+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:13.211+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:37:13.215+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:13.214+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:37:13.216+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:37:13.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.451 seconds
[2024-03-25T17:37:44.142+0000] {processor.py:161} INFO - Started process (PID=2709) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:37:44.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:37:44.145+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:44.145+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:37:48.432+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:48.430+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:37:48.563+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:48.563+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:37:48.564+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:48.564+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:37:48.565+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:48.565+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:37:48.569+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:37:48.567+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:37:48.569+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:37:48.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.436 seconds
[2024-03-25T17:38:19.444+0000] {processor.py:161} INFO - Started process (PID=2744) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:38:19.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:38:19.447+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:19.447+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:38:23.681+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:23.679+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:38:23.704+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:23.703+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:38:23.705+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:23.705+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:38:23.707+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:23.707+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:38:23.714+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:23.711+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:38:23.714+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:38:23.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.279 seconds
[2024-03-25T17:38:53.816+0000] {processor.py:161} INFO - Started process (PID=2779) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:38:53.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:38:53.820+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:53.819+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:38:58.062+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:58.059+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:38:58.087+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:58.087+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:38:58.089+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:58.089+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:38:58.092+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:58.091+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:38:58.100+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:38:58.097+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:38:58.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:38:58.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.296 seconds
[2024-03-25T17:39:29.078+0000] {processor.py:161} INFO - Started process (PID=2814) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:39:29.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:39:29.082+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:39:29.081+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:39:33.483+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:39:33.482+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:39:33.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:39:33.493+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:39:33.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:39:33.493+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:39:33.495+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:39:33.495+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:39:33.498+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:39:33.497+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:39:33.499+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:39:33.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.429 seconds
[2024-03-25T17:40:04.360+0000] {processor.py:161} INFO - Started process (PID=2849) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:40:04.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:40:04.362+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:04.362+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:40:08.836+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:08.832+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:40:08.863+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:08.863+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:40:08.865+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:08.865+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:40:08.867+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:08.867+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:40:08.873+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:08.871+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:40:08.874+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:40:08.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.525 seconds
[2024-03-25T17:40:39.599+0000] {processor.py:161} INFO - Started process (PID=2888) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:40:39.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:40:39.602+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:39.601+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:40:44.857+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:44.856+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:40:44.984+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:44.984+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:40:44.985+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:44.985+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:40:44.986+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:44.986+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:40:44.990+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:40:44.989+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:40:44.991+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:40:44.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.401 seconds
[2024-03-25T17:41:15.909+0000] {processor.py:161} INFO - Started process (PID=2937) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:41:15.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:41:15.911+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:15.910+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:41:20.135+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:20.134+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:41:20.151+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:20.151+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:41:20.152+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:20.152+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:41:20.154+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:20.154+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:41:20.160+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:20.158+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:41:20.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:41:20.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.261 seconds
[2024-03-25T17:41:50.228+0000] {processor.py:161} INFO - Started process (PID=2972) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:41:50.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:41:50.231+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:50.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:41:54.502+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:54.501+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:41:54.518+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:54.518+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:41:54.519+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:54.519+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:41:54.520+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:54.520+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:41:54.525+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:41:54.524+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:41:54.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:41:54.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.307 seconds
[2024-03-25T17:42:25.427+0000] {processor.py:161} INFO - Started process (PID=3007) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:42:25.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:42:25.430+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:42:25.430+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:42:29.980+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:42:29.978+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:42:30.004+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:42:30.004+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:42:30.006+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:42:30.006+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:42:30.008+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:42:30.007+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:42:30.014+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:42:30.012+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:42:30.015+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:42:30.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.598 seconds
[2024-03-25T17:43:00.643+0000] {processor.py:161} INFO - Started process (PID=3042) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:43:00.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:43:00.646+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:00.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:43:06.412+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:06.411+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:43:06.424+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:06.424+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:43:06.425+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:06.425+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:43:06.426+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:06.426+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:43:06.431+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:06.429+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:43:06.431+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:43:06.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.797 seconds
[2024-03-25T17:43:37.028+0000] {processor.py:161} INFO - Started process (PID=3077) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:43:37.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:43:37.031+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:37.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:43:41.282+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:41.281+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:43:41.299+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:41.298+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:43:41.300+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:41.300+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:43:41.302+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:41.302+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:43:41.307+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:43:41.305+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:43:41.308+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:43:41.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.290 seconds
[2024-03-25T17:44:12.281+0000] {processor.py:161} INFO - Started process (PID=3119) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:44:12.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:44:12.284+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:12.284+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:44:16.618+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:16.617+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:44:16.641+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:16.641+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:44:16.643+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:16.643+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:44:16.645+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:16.645+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:44:16.653+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:16.650+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:44:16.653+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:44:16.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.381 seconds
[2024-03-25T17:44:47.557+0000] {processor.py:161} INFO - Started process (PID=3160) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:44:47.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:44:47.560+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:47.559+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:44:51.890+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:51.889+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:44:51.902+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:51.902+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:44:51.902+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:51.902+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:44:51.904+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:51.904+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:44:51.908+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:44:51.906+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:44:51.908+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:44:51.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.359 seconds
[2024-03-25T17:45:21.952+0000] {processor.py:161} INFO - Started process (PID=3195) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:45:21.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:45:21.954+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:45:21.954+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:45:26.155+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:45:26.153+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:45:26.179+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:45:26.179+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:45:26.181+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:45:26.181+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:45:26.183+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:45:26.183+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:45:26.191+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:45:26.189+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:45:26.192+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:45:26.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.251 seconds
[2024-03-25T17:45:56.253+0000] {processor.py:161} INFO - Started process (PID=3230) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:45:56.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:45:56.257+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:45:56.256+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:46:00.507+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:00.507+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:46:00.519+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:00.519+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:46:00.520+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:00.520+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:46:00.522+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:00.522+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:46:00.527+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:00.525+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:46:00.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:46:00.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.284 seconds
[2024-03-25T17:46:30.565+0000] {processor.py:161} INFO - Started process (PID=3265) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:46:30.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:46:30.567+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:30.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:46:34.968+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:34.966+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:46:34.996+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:34.996+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:46:34.998+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:34.997+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:46:34.999+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:34.999+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:46:35.008+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:46:35.005+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:46:35.009+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:46:35.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.453 seconds
[2024-03-25T17:47:05.746+0000] {processor.py:161} INFO - Started process (PID=3300) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:47:05.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:47:05.748+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:05.748+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:47:10.033+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:10.032+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:47:10.052+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:10.052+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:47:10.054+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:10.054+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:47:10.055+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:10.055+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:47:10.061+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:10.059+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:47:10.061+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:47:10.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.323 seconds
[2024-03-25T17:47:41.056+0000] {processor.py:161} INFO - Started process (PID=3335) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:47:41.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:47:41.059+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:41.058+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:47:45.175+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:45.174+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:47:45.200+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:45.200+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:47:45.202+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:45.202+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:47:45.204+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:45.204+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:47:45.212+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:47:45.209+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:47:45.213+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:47:45.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.171 seconds
[2024-03-25T17:48:15.322+0000] {processor.py:161} INFO - Started process (PID=3370) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:48:15.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:48:15.325+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:15.324+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:48:19.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:19.533+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:48:19.544+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:19.544+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:48:19.546+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:19.546+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:48:19.547+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:19.547+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:48:19.553+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:19.550+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:48:19.553+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:48:19.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.241 seconds
[2024-03-25T17:48:49.707+0000] {processor.py:161} INFO - Started process (PID=3410) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:48:49.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:48:49.709+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:49.709+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:48:53.980+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:53.979+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:48:53.999+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:53.998+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:48:54.000+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:54.000+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:48:54.109+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:54.108+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:48:54.113+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:48:54.111+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:48:54.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:48:54.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.414 seconds
[2024-03-25T17:49:25.015+0000] {processor.py:161} INFO - Started process (PID=3445) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:49:25.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:49:25.018+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:49:25.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:49:29.517+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:49:29.517+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:49:29.527+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:49:29.526+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:49:29.527+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:49:29.527+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:49:29.528+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:49:29.528+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:49:29.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:49:29.531+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:49:29.533+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:49:29.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.524 seconds
[2024-03-25T17:50:00.257+0000] {processor.py:161} INFO - Started process (PID=3488) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:50:00.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:50:00.259+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:00.259+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:50:04.886+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:04.884+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:50:04.908+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:04.908+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:50:04.910+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:04.910+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:50:04.912+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:04.912+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:50:04.920+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:04.917+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:50:04.921+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:50:04.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.673 seconds
[2024-03-25T17:50:35.497+0000] {processor.py:161} INFO - Started process (PID=3523) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:50:35.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:50:35.500+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:35.499+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:50:39.978+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:39.976+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:50:40.001+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:40.001+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:50:40.003+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:40.003+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:50:40.004+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:40.004+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:50:40.011+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:50:40.008+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:50:40.011+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:50:40.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.524 seconds
[2024-03-25T17:51:10.811+0000] {processor.py:161} INFO - Started process (PID=3558) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:51:10.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:51:10.815+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:10.814+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:51:16.323+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:16.322+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:51:16.345+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:16.345+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:51:16.347+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:16.347+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:51:16.349+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:16.349+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:51:16.354+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:16.352+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:51:16.355+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:51:16.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.554 seconds
[2024-03-25T17:51:47.151+0000] {processor.py:161} INFO - Started process (PID=3593) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:51:47.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:51:47.156+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:47.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:51:52.249+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:52.248+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:51:52.262+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:52.262+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:51:52.263+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:52.263+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:51:52.386+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:52.386+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:51:52.391+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:51:52.389+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:51:52.392+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:51:52.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.251 seconds
[2024-03-25T17:52:22.548+0000] {processor.py:161} INFO - Started process (PID=3631) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:52:22.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:52:22.549+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:52:22.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:52:30.785+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:52:30.784+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:52:30.802+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:52:30.802+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:52:30.804+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:52:30.803+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:52:30.805+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:52:30.805+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:52:30.811+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:52:30.809+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:52:30.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:52:30.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 8.272 seconds
[2024-03-25T17:53:00.861+0000] {processor.py:161} INFO - Started process (PID=3674) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:53:00.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:53:00.864+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:53:00.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:53:09.999+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:53:09.998+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:53:10.015+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:53:10.015+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:53:10.016+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:53:10.016+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:53:10.018+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:53:10.018+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:53:10.024+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:53:10.022+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:53:10.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:53:10.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 9.174 seconds
[2024-03-25T17:56:25.634+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:56:25.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:56:25.635+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:56:25.635+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:56:32.110+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:56:32.110+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:56:32.124+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:56:32.122+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T17:56:32.125+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:56:32.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.499 seconds
[2024-03-25T17:57:03.083+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:57:03.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:57:03.084+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:03.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:57:10.018+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:10.017+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:57:10.038+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:10.036+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T17:57:10.039+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:57:10.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.968 seconds
[2024-03-25T17:57:40.329+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:57:40.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:57:40.332+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:40.331+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:57:48.218+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:48.217+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:57:48.234+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:48.234+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:57:48.236+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:48.236+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:57:48.237+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:48.237+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:57:48.245+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:57:48.244+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:57:48.246+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:57:48.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 7.926 seconds
[2024-03-25T17:58:18.529+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:58:18.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:58:18.531+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:58:18.531+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:58:23.798+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:58:23.796+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:58:23.821+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:58:23.821+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:58:23.823+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:58:23.823+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:58:23.825+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:58:23.825+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:58:23.830+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:58:23.828+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:58:23.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:58:23.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.313 seconds
[2024-03-25T17:58:54.796+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:58:54.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:58:54.798+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:58:54.798+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:59:00.858+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:00.856+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:59:00.876+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:00.876+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:59:00.878+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:00.878+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:59:00.879+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:00.879+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:59:00.885+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:00.883+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:59:00.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:59:00.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.099 seconds
[2024-03-25T17:59:31.145+0000] {processor.py:161} INFO - Started process (PID=366) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:59:31.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T17:59:31.148+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:31.147+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:59:36.907+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:36.906+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T17:59:36.923+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:36.923+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T17:59:36.930+0000] {logging_mixin.py:188} INFO - [2024-03-25T17:59:36.928+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T17:59:36.930+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T17:59:36.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.795 seconds
[2024-03-25T18:01:55.022+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:01:55.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:01:55.025+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:01:55.024+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:02:03.213+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:02:03.213+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:02:03.225+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:02:03.224+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T18:02:03.226+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:02:03.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 8.212 seconds
[2024-03-25T18:02:33.429+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:02:33.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:02:33.431+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:02:33.430+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:02:38.532+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:02:38.530+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:02:38.555+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:02:38.552+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 20, in build_exec_pipeline_sales_data
    conn_hook = MySqlHook.get_hook(mysql_connection_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 94, in get_hook
    connection = cls.get_connection(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/hooks/base.py", line 82, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 479, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `mysql_conn` isn't defined
[2024-03-25T18:02:38.556+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:02:38.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.136 seconds
[2024-03-25T18:03:08.786+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:03:08.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:03:08.789+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:08.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:03:13.928+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:13.928+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:03:13.940+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:13.940+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:03:13.944+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:13.942+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 23, in build_exec_pipeline_sales_data
    mysql_client = create_engine(mysql_url)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/pymysql.py", line 80, in dbapi
    return __import__("pymysql")
ModuleNotFoundError: No module named 'pymysql'
[2024-03-25T18:03:13.944+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:03:13.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.167 seconds
[2024-03-25T18:03:44.033+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:03:44.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:03:44.034+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:44.034+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:03:52.189+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:52.188+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:03:52.202+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:52.202+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:03:52.211+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:03:52.209+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:03:52.212+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:03:52.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 8.188 seconds
[2024-03-25T18:04:22.330+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:04:22.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:04:22.335+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:04:22.334+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:04:28.417+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:04:28.416+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:04:28.433+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:04:28.433+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:04:28.441+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:04:28.438+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:04:28.441+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:04:28.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.125 seconds
[2024-03-25T18:04:58.617+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:04:58.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:04:58.619+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:04:58.618+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:05:03.905+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:05:03.904+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:05:03.924+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:05:03.924+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:05:03.931+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:05:03.929+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:05:03.932+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:05:03.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.324 seconds
[2024-03-25T18:05:34.006+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:05:34.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:05:34.011+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:05:34.010+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:05:42.452+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:05:42.452+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:05:42.466+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:05:42.466+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:05:42.473+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:05:42.471+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:05:42.474+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:05:42.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 8.477 seconds
[2024-03-25T18:06:13.380+0000] {processor.py:161} INFO - Started process (PID=436) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:06:13.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:06:13.382+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:13.382+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:06:20.665+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:20.664+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:06:20.681+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:20.681+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:06:20.687+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:20.685+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:06:20.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:06:20.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 7.317 seconds
[2024-03-25T18:06:51.642+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:06:51.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:06:51.644+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:51.644+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:06:56.744+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:56.742+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:06:56.768+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:56.767+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:06:56.777+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:06:56.775+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:06:56.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:06:56.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.145 seconds
[2024-03-25T18:07:26.936+0000] {processor.py:161} INFO - Started process (PID=515) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:07:26.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:07:26.940+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:07:26.939+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:07:32.811+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:07:32.810+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:07:32.831+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:07:32.831+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:07:32.838+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:07:32.836+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:07:32.839+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:07:32.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.914 seconds
[2024-03-25T18:08:03.099+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:08:03.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:08:03.102+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:03.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:08:08.686+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:08.684+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:08:08.714+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:08.714+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:08:08.724+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:08.722+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:08:08.725+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:08:08.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.638 seconds
[2024-03-25T18:08:39.337+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:08:39.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:08:39.339+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:39.339+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:08:44.167+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:44.166+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:08:44.188+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:44.188+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:08:44.195+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:08:44.192+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:08:44.196+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:08:44.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.868 seconds
[2024-03-25T18:09:14.597+0000] {processor.py:161} INFO - Started process (PID=625) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:09:14.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:09:14.600+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:14.599+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:09:20.716+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:20.715+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:09:20.730+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:20.730+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:09:20.737+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:20.735+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:09:20.737+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:09:20.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.151 seconds
[2024-03-25T18:09:50.889+0000] {processor.py:161} INFO - Started process (PID=668) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:09:50.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:09:50.891+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:50.890+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:09:55.330+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:55.328+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:09:55.353+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:55.353+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:09:55.360+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:09:55.358+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:09:55.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:09:55.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.481 seconds
[2024-03-25T18:10:26.193+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:10:26.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:10:26.196+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:10:26.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:10:33.664+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:10:33.663+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:10:33.683+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:10:33.683+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:10:33.690+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:10:33.688+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:10:33.691+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:10:33.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 7.509 seconds
[2024-03-25T18:11:04.537+0000] {processor.py:161} INFO - Started process (PID=743) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:11:04.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:11:04.540+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:04.539+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:11:09.710+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:09.706+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:11:09.726+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:09.726+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:11:09.733+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:09.731+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:11:09.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:11:09.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.206 seconds
[2024-03-25T18:11:39.850+0000] {processor.py:161} INFO - Started process (PID=778) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:11:39.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:11:39.851+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:39.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:11:45.592+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:45.591+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:11:45.613+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:45.613+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:11:45.621+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:11:45.618+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:11:45.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:11:45.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.781 seconds
[2024-03-25T18:12:16.133+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:12:16.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:12:16.135+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:16.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:12:21.601+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:21.599+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:12:21.618+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:21.618+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:12:21.627+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:21.625+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:12:21.628+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:12:21.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.503 seconds
[2024-03-25T18:12:52.458+0000] {processor.py:161} INFO - Started process (PID=856) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:12:52.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:12:52.460+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:52.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:12:57.237+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:57.236+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:12:57.252+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:57.252+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:12:57.259+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:12:57.257+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:12:57.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:12:57.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.810 seconds
[2024-03-25T18:13:27.718+0000] {processor.py:161} INFO - Started process (PID=891) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:13:27.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:13:27.721+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:13:27.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:13:32.143+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:13:32.142+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:13:32.159+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:13:32.159+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:13:32.164+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:13:32.163+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:13:32.165+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:13:32.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.456 seconds
[2024-03-25T18:14:03.049+0000] {processor.py:161} INFO - Started process (PID=932) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:14:03.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:14:03.052+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:03.051+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:14:08.353+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:08.352+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:14:08.369+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:08.369+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:14:08.384+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:08.379+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:14:08.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:14:08.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.356 seconds
[2024-03-25T18:14:39.333+0000] {processor.py:161} INFO - Started process (PID=967) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:14:39.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:14:39.336+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:39.335+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:14:44.461+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:44.460+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:14:44.479+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:44.479+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:14:44.485+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:14:44.483+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:14:44.486+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:14:44.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.164 seconds
[2024-03-25T18:15:14.549+0000] {processor.py:161} INFO - Started process (PID=1009) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:15:14.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:15:14.551+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:14.550+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:15:19.384+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:19.382+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:15:19.410+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:19.410+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:15:19.421+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:19.418+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:15:19.422+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:15:19.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.882 seconds
[2024-03-25T18:15:49.806+0000] {processor.py:161} INFO - Started process (PID=1045) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:15:49.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:15:49.809+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:49.808+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:15:54.199+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:54.198+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:15:54.216+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:54.216+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:15:54.223+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:15:54.221+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:15:54.224+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:15:54.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.430 seconds
[2024-03-25T18:16:25.051+0000] {processor.py:161} INFO - Started process (PID=1081) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:16:25.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:16:25.054+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:16:25.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:16:29.465+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:16:29.464+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:16:29.476+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:16:29.476+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:16:29.481+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:16:29.479+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:16:29.481+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:16:29.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.439 seconds
[2024-03-25T18:17:00.300+0000] {processor.py:161} INFO - Started process (PID=1116) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:17:00.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:17:00.302+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:00.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:17:04.531+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:04.530+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:17:04.547+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:04.547+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:17:04.555+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:04.553+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:17:04.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:17:04.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.263 seconds
[2024-03-25T18:17:34.709+0000] {processor.py:161} INFO - Started process (PID=1156) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:17:34.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:17:34.711+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:34.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:17:39.934+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:39.934+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:17:39.947+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:39.947+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:17:39.952+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:17:39.950+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:17:39.953+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:17:39.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.257 seconds
[2024-03-25T18:18:10.001+0000] {processor.py:161} INFO - Started process (PID=1191) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:18:10.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:18:10.003+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:10.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:18:17.478+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:17.478+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:18:17.491+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:17.491+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:18:17.498+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:17.496+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:18:17.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:18:17.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 7.506 seconds
[2024-03-25T18:18:48.201+0000] {processor.py:161} INFO - Started process (PID=1234) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:18:48.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:18:48.203+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:48.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:18:54.334+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:54.333+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:18:54.349+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:54.349+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:18:54.356+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:18:54.354+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:18:54.356+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:18:54.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.163 seconds
[2024-03-25T18:19:24.505+0000] {processor.py:161} INFO - Started process (PID=1268) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:19:24.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:19:24.507+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:19:24.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:19:30.095+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:19:30.093+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:19:30.113+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:19:30.113+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:19:30.121+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:19:30.119+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:19:30.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:19:30.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.625 seconds
[2024-03-25T18:20:00.778+0000] {processor.py:161} INFO - Started process (PID=1303) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:20:00.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:20:00.780+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:00.780+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:20:07.522+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:07.520+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:20:07.540+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:07.540+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:20:07.548+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:07.546+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:20:07.549+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:20:07.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.779 seconds
[2024-03-25T18:20:38.199+0000] {processor.py:161} INFO - Started process (PID=1343) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:20:38.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:20:38.201+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:38.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:20:42.702+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:42.701+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:20:42.725+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:42.725+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:20:42.732+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:20:42.730+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:20:42.733+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:20:42.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.542 seconds
[2024-03-25T18:21:13.470+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:21:13.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:21:13.472+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:13.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:21:18.320+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:18.319+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:21:18.339+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:18.339+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:21:18.478+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:18.476+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:21:18.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:21:18.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.017 seconds
[2024-03-25T18:21:48.665+0000] {processor.py:161} INFO - Started process (PID=1421) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:21:48.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:21:48.668+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:48.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:21:54.324+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:54.323+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:21:54.350+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:54.350+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:21:54.359+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:21:54.356+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:21:54.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:21:54.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.706 seconds
[2024-03-25T18:22:24.979+0000] {processor.py:161} INFO - Started process (PID=1456) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:22:24.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:22:24.983+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:22:24.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:22:31.125+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:22:31.122+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:22:31.153+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:22:31.152+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:22:31.163+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:22:31.160+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:22:31.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:22:31.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 6.197 seconds
[2024-03-25T18:23:01.239+0000] {processor.py:161} INFO - Started process (PID=1491) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:23:01.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:23:01.241+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:01.241+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:23:06.185+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:06.183+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:23:06.207+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:06.207+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:23:06.215+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:06.212+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:23:06.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:23:06.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.985 seconds
[2024-03-25T18:23:36.467+0000] {processor.py:161} INFO - Started process (PID=1531) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:23:36.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:23:36.471+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:36.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:23:40.936+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:40.936+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:23:40.949+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:40.949+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:23:40.955+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:23:40.953+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:23:40.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:23:40.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.498 seconds
[2024-03-25T18:24:11.691+0000] {processor.py:161} INFO - Started process (PID=1566) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:24:11.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:24:11.696+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:11.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:24:16.019+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:16.018+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:24:16.041+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:16.041+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:24:16.157+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:16.155+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:24:16.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:24:16.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.476 seconds
[2024-03-25T18:24:46.977+0000] {processor.py:161} INFO - Started process (PID=1601) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:24:46.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:24:46.980+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:46.979+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:24:52.085+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:52.083+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:24:52.112+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:52.112+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:24:52.122+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:24:52.118+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:24:52.123+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:24:52.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 5.159 seconds
[2024-03-25T18:25:22.354+0000] {processor.py:161} INFO - Started process (PID=1644) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:25:22.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:25:22.357+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:25:22.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:25:26.773+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:25:26.771+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:25:26.802+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:25:26.802+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:25:26.810+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:25:26.808+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:25:26.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:25:26.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.468 seconds
[2024-03-25T18:25:57.617+0000] {processor.py:161} INFO - Started process (PID=1679) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:25:57.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:25:57.619+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:25:57.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:26:01.884+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:26:01.882+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:26:01.908+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:26:01.908+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:26:01.917+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:26:01.915+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 24, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:26:01.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:26:01.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.313 seconds
[2024-03-25T18:26:32.962+0000] {processor.py:161} INFO - Started process (PID=1714) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:26:32.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:26:32.967+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:26:32.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:26:37.890+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:26:37.888+0000] {connection.py:473} ERROR - Unable to retrieve connection from secrets backend (LocalFilesystemBackend). Checking subsequent secrets backend.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/connection.py", line 468, in get_connection_from_secrets
    conn = secrets_backend.get_connection(conn_id=conn_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 316, in get_connection
    if conn_id in self._local_connections:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 313, in _local_connections
    return load_connections_dict(self.connections_file)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 265, in load_connections_dict
    secrets: dict[str, Any] = _parse_secret_file(file_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/secrets/local_filesystem.py", line 162, in _parse_secret_file
    raise AirflowException(
airflow.exceptions.AirflowException: File /opt/secrets/connections.yaml was not found. Check the configuration of your Secrets backend.
[2024-03-25T18:26:37.915+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:26:37.915+0000] {base.py:83} INFO - Using connection ID 'mysql_conn' for task execution.
[2024-03-25T18:26:37.926+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:26:37.922+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 25, in build_exec_pipeline_sales_data
    engine = create_engine(mysql_client)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py", line 375, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 516, in create_engine
    u, plugins, kwargs = u._instantiate_plugins(kwargs)
AttributeError: 'Engine' object has no attribute '_instantiate_plugins'
[2024-03-25T18:26:37.926+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:26:37.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 4.978 seconds
[2024-03-25T18:27:08.281+0000] {processor.py:161} INFO - Started process (PID=1754) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:27:08.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:27:08.284+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:27:08.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:27:08.442+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:27:08.440+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:27:08.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:27:08.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.180 seconds
[2024-03-25T18:27:38.642+0000] {processor.py:161} INFO - Started process (PID=1789) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:27:38.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:27:38.647+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:27:38.646+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:27:38.817+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:27:38.815+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:27:38.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:27:38.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.193 seconds
[2024-03-25T18:28:08.938+0000] {processor.py:161} INFO - Started process (PID=1816) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:28:08.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:28:08.941+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:28:08.940+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:28:09.092+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:28:09.090+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:28:09.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:28:09.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.170 seconds
[2024-03-25T18:28:39.313+0000] {processor.py:161} INFO - Started process (PID=1851) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:28:39.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:28:39.316+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:28:39.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:28:39.501+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:28:39.499+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:28:39.502+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:28:39.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.207 seconds
[2024-03-25T18:29:09.647+0000] {processor.py:161} INFO - Started process (PID=1886) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:29:09.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:29:09.649+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:29:09.649+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:29:09.811+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:29:09.809+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:29:09.812+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:29:09.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.180 seconds
[2024-03-25T18:29:39.864+0000] {processor.py:161} INFO - Started process (PID=1921) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:29:39.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:29:39.866+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:29:39.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:29:40.019+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:29:40.017+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:29:40.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:29:40.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.173 seconds
[2024-03-25T18:30:10.136+0000] {processor.py:161} INFO - Started process (PID=1948) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:30:10.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:30:10.138+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:30:10.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:30:10.284+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:30:10.283+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:30:10.285+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:30:10.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.165 seconds
[2024-03-25T18:30:40.414+0000] {processor.py:161} INFO - Started process (PID=1983) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:30:40.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:30:40.415+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:30:40.415+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:30:40.574+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:30:40.572+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:30:40.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:30:40.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.176 seconds
[2024-03-25T18:31:10.701+0000] {processor.py:161} INFO - Started process (PID=2018) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:31:10.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:31:10.704+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:31:10.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:31:10.865+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:31:10.863+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:31:10.865+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:31:10.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.182 seconds
[2024-03-25T18:31:40.906+0000] {processor.py:161} INFO - Started process (PID=2045) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:31:40.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:31:40.908+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:31:40.908+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:31:41.041+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:31:41.039+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:31:41.041+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:31:41.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.151 seconds
[2024-03-25T18:32:11.274+0000] {processor.py:161} INFO - Started process (PID=2080) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:32:11.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:32:11.278+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:32:11.277+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:32:11.444+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:32:11.442+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:32:11.445+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:32:11.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.187 seconds
[2024-03-25T18:32:41.511+0000] {processor.py:161} INFO - Started process (PID=2114) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:32:41.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:32:41.512+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:32:41.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:32:41.642+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:32:41.640+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:32:41.642+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:32:41.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.146 seconds
[2024-03-25T18:33:11.836+0000] {processor.py:161} INFO - Started process (PID=2148) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:33:11.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:33:11.839+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:33:11.838+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:33:11.976+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:33:11.974+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:33:11.977+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:33:11.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T18:33:42.177+0000] {processor.py:161} INFO - Started process (PID=2176) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:33:42.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:33:42.178+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:33:42.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:33:42.361+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:33:42.359+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:33:42.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:33:42.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.202 seconds
[2024-03-25T18:34:12.437+0000] {processor.py:161} INFO - Started process (PID=2211) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:34:12.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:34:12.440+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:34:12.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:34:12.601+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:34:12.599+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:34:12.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:34:12.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.184 seconds
[2024-03-25T18:34:42.722+0000] {processor.py:161} INFO - Started process (PID=2246) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:34:42.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:34:42.724+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:34:42.723+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:34:42.868+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:34:42.866+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:34:42.869+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:34:42.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.165 seconds
[2024-03-25T18:35:13.102+0000] {processor.py:161} INFO - Started process (PID=2273) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:35:13.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:35:13.104+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:35:13.104+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:35:13.279+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:35:13.276+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:35:13.279+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:35:13.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.191 seconds
[2024-03-25T18:35:43.417+0000] {processor.py:161} INFO - Started process (PID=2308) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:35:43.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:35:43.419+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:35:43.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:35:43.547+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:35:43.545+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:35:43.547+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:35:43.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.144 seconds
[2024-03-25T18:36:13.620+0000] {processor.py:161} INFO - Started process (PID=2343) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:36:13.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:36:13.623+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:36:13.623+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:36:13.778+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:36:13.776+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:36:13.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:36:13.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.174 seconds
[2024-03-25T18:36:43.940+0000] {processor.py:161} INFO - Started process (PID=2378) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:36:43.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:36:43.941+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:36:43.941+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:36:44.076+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:36:44.074+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:36:44.077+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:36:44.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.151 seconds
[2024-03-25T18:37:14.158+0000] {processor.py:161} INFO - Started process (PID=2405) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:37:14.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:37:14.162+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:37:14.161+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:37:14.309+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:37:14.308+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:37:14.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:37:14.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.169 seconds
[2024-03-25T18:37:44.445+0000] {processor.py:161} INFO - Started process (PID=2440) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:37:44.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:37:44.448+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:37:44.447+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:37:44.584+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:37:44.583+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:37:44.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:37:44.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T18:38:14.636+0000] {processor.py:161} INFO - Started process (PID=2474) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:38:14.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:38:14.639+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:38:14.639+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:38:14.813+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:38:14.811+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:38:14.814+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:38:14.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.193 seconds
[2024-03-25T18:38:44.907+0000] {processor.py:161} INFO - Started process (PID=2501) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:38:44.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:38:44.909+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:38:44.909+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:38:45.062+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:38:45.060+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:38:45.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:38:45.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.173 seconds
[2024-03-25T18:39:15.213+0000] {processor.py:161} INFO - Started process (PID=2536) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:39:15.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:39:15.215+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:39:15.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:39:15.412+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:39:15.410+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:39:15.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:39:15.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.219 seconds
[2024-03-25T18:39:45.494+0000] {processor.py:161} INFO - Started process (PID=2571) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:39:45.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:39:45.497+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:39:45.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:39:45.636+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:39:45.634+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:39:45.636+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:39:45.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.159 seconds
[2024-03-25T18:40:15.720+0000] {processor.py:161} INFO - Started process (PID=2605) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:40:15.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:40:15.722+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:40:15.722+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:40:15.880+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:40:15.878+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:40:15.880+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:40:15.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T18:40:46.077+0000] {processor.py:161} INFO - Started process (PID=2633) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:40:46.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:40:46.080+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:40:46.080+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:40:46.215+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:40:46.213+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:40:46.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:40:46.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T18:41:16.375+0000] {processor.py:161} INFO - Started process (PID=2668) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:41:16.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:41:16.378+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:41:16.378+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:41:16.517+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:41:16.515+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:41:16.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:41:16.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.157 seconds
[2024-03-25T18:41:46.577+0000] {processor.py:161} INFO - Started process (PID=2702) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:41:46.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:41:46.579+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:41:46.579+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:41:46.728+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:41:46.725+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:41:46.728+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:41:46.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.166 seconds
[2024-03-25T18:42:16.928+0000] {processor.py:161} INFO - Started process (PID=2729) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:42:16.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:42:16.930+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:16.930+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:42:17.078+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:17.076+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/opt/airflow/dags/common.py", line 14, in build_exec_pipeline_sales_data
    users_sales_data_df = pd.merge(users_data_df, sales_data_df, left_on='id', right_on='customer_id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 148, in merge
    op = _MergeOperation(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 680, in __init__
    _left = _validate_operand(left)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py", line 2575, in _validate_operand
    raise TypeError(
TypeError: Can only merge Series or DataFrame objects, a <class 'airflow.models.xcom_arg.PlainXComArg'> was passed
[2024-03-25T18:42:17.079+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:42:17.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.168 seconds
[2024-03-25T18:42:47.198+0000] {processor.py:161} INFO - Started process (PID=2763) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:42:47.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:42:47.201+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:47.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:42:47.361+0000] {processor.py:840} INFO - DAG(s) 'sales_data_pipeline' retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:42:47.526+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:47.526+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:sales_data_pipeline
[2024-03-25T18:42:47.530+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:47.530+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:sales_data_pipeline
[2024-03-25T18:42:47.532+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:47.532+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:sales_data_pipeline
[2024-03-25T18:42:47.533+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:47.532+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-03-25T18:42:47.537+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:47.536+0000] {dag.py:3055} INFO - Creating ORM DAG for sales_data_pipeline
[2024-03-25T18:42:47.542+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:42:47.542+0000] {dag.py:3820} INFO - Setting next_dagrun for sales_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
[2024-03-25T18:42:47.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.355 seconds
[2024-03-25T18:43:18.440+0000] {processor.py:161} INFO - Started process (PID=2798) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:43:18.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:43:18.442+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:43:18.442+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:43:18.585+0000] {processor.py:840} INFO - DAG(s) 'sales_data_pipeline' retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:43:18.600+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:43:18.599+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-03-25T18:43:18.611+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:43:18.611+0000] {dag.py:3820} INFO - Setting next_dagrun for sales_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
[2024-03-25T18:43:18.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.257 seconds
[2024-03-25T18:43:48.788+0000] {processor.py:161} INFO - Started process (PID=2833) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:43:48.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:43:48.790+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:43:48.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:43:48.923+0000] {processor.py:840} INFO - DAG(s) 'sales_data_pipeline' retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:43:48.939+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:43:48.938+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-03-25T18:43:49.042+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:43:49.042+0000] {dag.py:3820} INFO - Setting next_dagrun for sales_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
[2024-03-25T18:43:49.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.266 seconds
[2024-03-25T18:44:19.127+0000] {processor.py:161} INFO - Started process (PID=2860) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:44:19.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:44:19.130+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:44:19.129+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:44:19.312+0000] {processor.py:840} INFO - DAG(s) 'sales_data_pipeline' retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:44:19.333+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:44:19.333+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-03-25T18:44:19.429+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:44:19.429+0000] {dag.py:3820} INFO - Setting next_dagrun for sales_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
[2024-03-25T18:44:19.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.313 seconds
[2024-03-25T18:44:50.345+0000] {processor.py:161} INFO - Started process (PID=2895) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:44:50.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:44:50.347+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:44:50.347+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:44:50.511+0000] {processor.py:840} INFO - DAG(s) 'sales_data_pipeline' retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:44:50.622+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:44:50.622+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-03-25T18:44:50.632+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:44:50.632+0000] {dag.py:3820} INFO - Setting next_dagrun for sales_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
[2024-03-25T18:44:50.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.298 seconds
[2024-03-25T18:45:20.664+0000] {processor.py:161} INFO - Started process (PID=2931) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:45:20.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:45:20.666+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:45:20.666+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:45:20.822+0000] {processor.py:840} INFO - DAG(s) 'sales_data_pipeline' retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:45:20.838+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:45:20.838+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-03-25T18:45:20.849+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:45:20.849+0000] {dag.py:3820} INFO - Setting next_dagrun for sales_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
[2024-03-25T18:45:20.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.196 seconds
[2024-03-25T18:45:50.901+0000] {processor.py:161} INFO - Started process (PID=2966) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:45:50.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:45:50.906+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:45:50.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:45:51.042+0000] {processor.py:840} INFO - DAG(s) 'sales_data_pipeline' retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:45:51.057+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:45:51.057+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-03-25T18:45:51.068+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:45:51.068+0000] {dag.py:3820} INFO - Setting next_dagrun for sales_data_pipeline to 2024-03-24T00:00:00+00:00, run_after=2024-03-25T00:00:00+00:00
[2024-03-25T18:45:51.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T18:46:21.305+0000] {processor.py:161} INFO - Started process (PID=2993) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:46:21.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:46:21.309+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:46:21.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:46:21.483+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:46:21.479+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/python.py", line 52, in __init__
    super().__init__(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 229, in __init__
    signature.bind(*op_args, **op_kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 3037, in bind
    return self._bind(args, kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 2952, in _bind
    raise TypeError(msg) from None
TypeError: missing a required argument: 'sales_data_df'
[2024-03-25T18:46:21.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:46:21.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.198 seconds
[2024-03-25T18:46:51.569+0000] {processor.py:161} INFO - Started process (PID=3028) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:46:51.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:46:51.570+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:46:51.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:46:51.709+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:46:51.707+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/python.py", line 52, in __init__
    super().__init__(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 229, in __init__
    signature.bind(*op_args, **op_kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 3037, in bind
    return self._bind(args, kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 2952, in _bind
    raise TypeError(msg) from None
TypeError: missing a required argument: 'sales_data_df'
[2024-03-25T18:46:51.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:46:51.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.157 seconds
[2024-03-25T18:47:21.768+0000] {processor.py:161} INFO - Started process (PID=3063) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:47:21.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:47:21.772+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:47:21.771+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:47:21.929+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:47:21.927+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/python.py", line 52, in __init__
    super().__init__(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 229, in __init__
    signature.bind(*op_args, **op_kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 3037, in bind
    return self._bind(args, kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 2952, in _bind
    raise TypeError(msg) from None
TypeError: missing a required argument: 'sales_data_df'
[2024-03-25T18:47:21.929+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:47:21.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.178 seconds
[2024-03-25T18:47:52.112+0000] {processor.py:161} INFO - Started process (PID=3090) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:47:52.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:47:52.113+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:47:52.113+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:47:52.267+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:47:52.266+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 34, in <module>
    sales_data_pipeline()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3941, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/sales_data_pipeline.py", line 32, in sales_data_pipeline
    build_exec_pipeline_sales_data()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/python.py", line 52, in __init__
    super().__init__(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 229, in __init__
    signature.bind(*op_args, **op_kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 3037, in bind
    return self._bind(args, kwargs)
  File "/usr/local/lib/python3.8/inspect.py", line 2952, in _bind
    raise TypeError(msg) from None
TypeError: missing a required argument: 'sales_data_df'
[2024-03-25T18:47:52.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:47:52.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T18:48:22.358+0000] {processor.py:161} INFO - Started process (PID=3125) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:48:22.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:48:22.361+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:48:22.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:48:22.522+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:48:22.520+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 98, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:48:22.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:48:22.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T18:48:52.601+0000] {processor.py:161} INFO - Started process (PID=3160) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:48:52.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:48:52.603+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:48:52.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:48:52.752+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:48:52.750+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 98, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:48:52.753+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:48:52.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.168 seconds
[2024-03-25T18:49:22.936+0000] {processor.py:161} INFO - Started process (PID=3195) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:49:22.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:49:22.938+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:49:22.938+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:49:23.082+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:49:23.079+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 98, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:49:23.082+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:49:23.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.164 seconds
[2024-03-25T18:49:53.181+0000] {processor.py:161} INFO - Started process (PID=3222) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:49:53.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:49:53.183+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:49:53.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:49:53.368+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:49:53.365+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 98, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:49:53.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:49:53.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.204 seconds
[2024-03-25T18:50:23.448+0000] {processor.py:161} INFO - Started process (PID=3257) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:50:23.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:50:23.450+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:50:23.450+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:50:23.592+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:50:23.590+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:50:23.592+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:50:23.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.161 seconds
[2024-03-25T18:50:53.755+0000] {processor.py:161} INFO - Started process (PID=3292) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:50:53.756+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:50:53.757+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:50:53.757+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:50:54.004+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:50:54.001+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:50:54.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:50:54.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.266 seconds
[2024-03-25T18:51:24.136+0000] {processor.py:161} INFO - Started process (PID=3319) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:51:24.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:51:24.141+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:51:24.140+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:51:24.308+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:51:24.305+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:51:24.308+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:51:24.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.195 seconds
[2024-03-25T18:51:54.393+0000] {processor.py:161} INFO - Started process (PID=3354) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:51:54.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:51:54.396+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:51:54.395+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:51:54.575+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:51:54.572+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:51:54.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:51:54.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.198 seconds
[2024-03-25T18:52:24.696+0000] {processor.py:161} INFO - Started process (PID=3389) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:52:24.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:52:24.698+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:52:24.698+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:52:24.855+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:52:24.852+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:52:24.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:52:24.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T18:52:41.813+0000] {processor.py:161} INFO - Started process (PID=3403) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:52:41.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:52:41.815+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:52:41.815+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:52:41.952+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:52:41.949+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:52:41.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:52:41.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.156 seconds
[2024-03-25T18:53:12.014+0000] {processor.py:161} INFO - Started process (PID=3438) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:53:12.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:53:12.016+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:53:12.016+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:53:12.187+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:53:12.184+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:53:12.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:53:12.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.193 seconds
[2024-03-25T18:53:42.325+0000] {processor.py:161} INFO - Started process (PID=3473) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:53:42.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:53:42.327+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:53:42.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:53:42.485+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:53:42.483+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:53:42.486+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:53:42.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T18:54:12.537+0000] {processor.py:161} INFO - Started process (PID=3500) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:54:12.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:54:12.540+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:54:12.540+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:54:12.696+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:54:12.692+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:54:12.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:54:12.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T18:54:42.800+0000] {processor.py:161} INFO - Started process (PID=3535) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:54:42.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:54:42.802+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:54:42.802+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:54:42.944+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:54:42.942+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:54:42.945+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:54:42.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T18:55:13.098+0000] {processor.py:161} INFO - Started process (PID=3570) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:13.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:55:13.101+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:13.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:13.268+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:13.264+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:55:13.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:13.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.191 seconds
[2024-03-25T18:55:43.351+0000] {processor.py:161} INFO - Started process (PID=3605) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:43.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:55:43.352+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:43.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:43.518+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:43.516+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:55:43.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:43.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.184 seconds
[2024-03-25T18:55:46.595+0000] {processor.py:161} INFO - Started process (PID=3611) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:46.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:55:46.597+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:46.597+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:46.727+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:46.725+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:55:46.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:46.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.147 seconds
[2024-03-25T18:55:55.683+0000] {processor.py:161} INFO - Started process (PID=3630) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:55.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:55:55.687+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:55.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:55.851+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:55:55.848+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:55:55.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:55:55.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.186 seconds
[2024-03-25T18:56:12.851+0000] {processor.py:161} INFO - Started process (PID=3644) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:12.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:56:12.853+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:56:12.852+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:13.002+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:56:13.000+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:56:13.002+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:13.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.170 seconds
[2024-03-25T18:56:32.132+0000] {processor.py:161} INFO - Started process (PID=3671) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:32.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:56:32.134+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:56:32.134+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:32.305+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:56:32.301+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:56:32.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:32.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.190 seconds
[2024-03-25T18:56:44.266+0000] {processor.py:161} INFO - Started process (PID=3685) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:44.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:56:44.270+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:56:44.270+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:44.421+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:56:44.418+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:56:44.421+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:56:44.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.172 seconds
[2024-03-25T18:57:14.702+0000] {processor.py:161} INFO - Started process (PID=3720) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:14.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:57:14.704+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:14.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:14.862+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:14.860+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:57:14.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:14.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.180 seconds
[2024-03-25T18:57:15.739+0000] {processor.py:161} INFO - Started process (PID=3726) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:15.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:57:15.742+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:15.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:15.886+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:15.883+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:57:15.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:15.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.165 seconds
[2024-03-25T18:57:44.147+0000] {processor.py:161} INFO - Started process (PID=3753) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:44.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:57:44.149+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:44.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:44.157+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:44.156+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 82
    api_url = f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}'
    ^
IndentationError: expected an indented block
[2024-03-25T18:57:44.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:44.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.030 seconds
[2024-03-25T18:57:45.177+0000] {processor.py:161} INFO - Started process (PID=3758) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:45.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:57:45.179+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:45.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:45.183+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:57:45.182+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 82
    api_url = f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}'
    ^
IndentationError: expected an indented block
[2024-03-25T18:57:45.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:57:45.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.027 seconds
[2024-03-25T18:58:15.457+0000] {processor.py:161} INFO - Started process (PID=3792) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:58:15.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:58:15.461+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:58:15.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:58:15.468+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:58:15.467+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 82
    api_url = f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}'
    ^
IndentationError: expected an indented block
[2024-03-25T18:58:15.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:58:15.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.035 seconds
[2024-03-25T18:58:40.649+0000] {processor.py:161} INFO - Started process (PID=3818) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:58:40.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:58:40.652+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:58:40.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:58:40.657+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:58:40.656+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 82
    api_url = f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}'
    ^
IndentationError: expected an indented block
[2024-03-25T18:58:40.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:58:40.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.033 seconds
[2024-03-25T18:59:10.858+0000] {processor.py:161} INFO - Started process (PID=3852) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:10.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:59:10.859+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:59:10.859+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:10.863+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:59:10.862+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 82
    api_url = f'https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}'
    ^
IndentationError: expected an indented block
[2024-03-25T18:59:10.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:10.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.021 seconds
[2024-03-25T18:59:24.957+0000] {processor.py:161} INFO - Started process (PID=3865) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:24.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:59:24.960+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:59:24.959+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:25.241+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:59:25.238+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:59:25.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:25.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.301 seconds
[2024-03-25T18:59:56.191+0000] {processor.py:161} INFO - Started process (PID=3900) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:56.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T18:59:56.193+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:59:56.193+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:56.330+0000] {logging_mixin.py:188} INFO - [2024-03-25T18:59:56.327+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T18:59:56.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T18:59:56.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.156 seconds
[2024-03-25T19:00:26.438+0000] {processor.py:161} INFO - Started process (PID=3935) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:00:26.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:00:26.440+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:00:26.440+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:00:26.609+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:00:26.607+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:00:26.610+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:00:26.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.187 seconds
[2024-03-25T19:00:56.658+0000] {processor.py:161} INFO - Started process (PID=3970) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:00:56.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:00:56.660+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:00:56.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:00:56.803+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:00:56.801+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:00:56.804+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:00:56.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T19:00:59.898+0000] {processor.py:161} INFO - Started process (PID=3981) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:00:59.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:00:59.901+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:00:59.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:00.036+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:00.034+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:01:00.037+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:00.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.156 seconds
[2024-03-25T19:01:13.174+0000] {processor.py:161} INFO - Started process (PID=3995) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:13.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:01:13.176+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:13.176+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:13.338+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:13.336+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:01:13.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:13.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.185 seconds
[2024-03-25T19:01:19.221+0000] {processor.py:161} INFO - Started process (PID=4009) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:19.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:01:19.222+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:19.222+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:19.520+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:19.517+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:01:19.521+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:19.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.313 seconds
[2024-03-25T19:01:49.610+0000] {processor.py:161} INFO - Started process (PID=4036) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:49.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:01:49.612+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:49.612+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:49.762+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:49.759+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:01:49.762+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:49.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.170 seconds
[2024-03-25T19:01:58.762+0000] {processor.py:161} INFO - Started process (PID=4055) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:58.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:01:58.764+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:58.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:58.922+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:01:58.919+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:01:58.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:01:58.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T19:02:12.943+0000] {processor.py:161} INFO - Started process (PID=4070) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:12.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:02:12.948+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:02:12.947+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:13.117+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:02:13.114+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:02:13.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:13.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.197 seconds
[2024-03-25T19:02:23.202+0000] {processor.py:161} INFO - Started process (PID=4084) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:23.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:02:23.204+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:02:23.203+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:23.343+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:02:23.341+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:02:23.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:23.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.157 seconds
[2024-03-25T19:02:36.334+0000] {processor.py:161} INFO - Started process (PID=4103) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:36.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:02:36.336+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:02:36.336+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:36.479+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:02:36.477+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:02:36.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:02:36.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T19:03:06.549+0000] {processor.py:161} INFO - Started process (PID=4138) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:06.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:03:06.551+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:06.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:06.715+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:06.712+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:03:06.715+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:06.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.182 seconds
[2024-03-25T19:03:25.740+0000] {processor.py:161} INFO - Started process (PID=4160) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:25.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:03:25.744+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:25.743+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:25.885+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:25.882+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:03:25.885+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:25.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.162 seconds
[2024-03-25T19:03:48.083+0000] {processor.py:161} INFO - Started process (PID=4187) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:48.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:03:48.085+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:48.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:48.328+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:48.326+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:03:48.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:48.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.259 seconds
[2024-03-25T19:03:52.136+0000] {processor.py:161} INFO - Started process (PID=4193) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:52.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:03:52.137+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:52.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:52.360+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:52.358+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:03:52.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:52.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.238 seconds
[2024-03-25T19:03:53.412+0000] {processor.py:161} INFO - Started process (PID=4199) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:53.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:03:53.415+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:53.414+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:53.657+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:03:53.655+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:03:53.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:03:53.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.261 seconds
[2024-03-25T19:04:17.575+0000] {processor.py:161} INFO - Started process (PID=4234) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:04:17.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:04:17.577+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:04:17.576+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:04:17.724+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:04:17.720+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:04:17.725+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:04:17.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.166 seconds
[2024-03-25T19:04:47.812+0000] {processor.py:161} INFO - Started process (PID=4261) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:04:47.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:04:47.814+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:04:47.814+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:04:47.986+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:04:47.982+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:04:47.986+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:04:48.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.193 seconds
[2024-03-25T19:05:18.110+0000] {processor.py:161} INFO - Started process (PID=4296) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:18.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:05:18.115+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:05:18.114+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:18.268+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:05:18.266+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:05:18.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:18.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.176 seconds
[2024-03-25T19:05:48.342+0000] {processor.py:161} INFO - Started process (PID=4331) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:48.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:05:48.344+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:05:48.344+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:48.522+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:05:48.519+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:05:48.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:48.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.197 seconds
[2024-03-25T19:05:54.417+0000] {processor.py:161} INFO - Started process (PID=4337) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:54.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:05:54.420+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:05:54.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:54.561+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:05:54.559+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:05:54.562+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:05:54.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T19:06:07.708+0000] {processor.py:161} INFO - Started process (PID=4356) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:07.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:06:07.711+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:07.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:08.016+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:08.012+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:06:08.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:08.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.327 seconds
[2024-03-25T19:06:08.787+0000] {processor.py:161} INFO - Started process (PID=4362) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:08.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:06:08.789+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:08.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:09.088+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:09.085+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:06:09.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:09.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.321 seconds
[2024-03-25T19:06:28.199+0000] {processor.py:161} INFO - Started process (PID=4384) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:28.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:06:28.202+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:28.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:28.461+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:28.458+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:06:28.461+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:28.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.278 seconds
[2024-03-25T19:06:59.473+0000] {processor.py:161} INFO - Started process (PID=4419) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:59.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:06:59.475+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:59.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:59.753+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:06:59.750+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:06:59.753+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:06:59.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.298 seconds
[2024-03-25T19:09:05.351+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:09:05.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:09:05.353+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:09:05.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:09:06.037+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:09:06.035+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:09:06.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:09:06.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.705 seconds
[2024-03-25T19:09:36.760+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:09:36.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:09:36.762+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:09:36.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:09:36.926+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:09:36.923+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:09:36.926+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:09:36.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T19:10:07.143+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:10:07.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:10:07.145+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:10:07.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:10:07.306+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:10:07.303+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:10:07.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:10:07.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.179 seconds
[2024-03-25T19:10:37.384+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:10:37.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:10:37.386+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:10:37.386+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:10:37.518+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:10:37.516+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:10:37.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:10:37.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.150 seconds
[2024-03-25T19:11:07.679+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:07.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:11:07.681+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:11:07.681+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:07.838+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:11:07.834+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:11:07.838+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:07.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T19:11:38.043+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:38.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:11:38.045+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:11:38.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:38.206+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:11:38.203+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 15, in <module>
    from common import build_exec_pipeline_sales_data
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:11:38.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:38.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.182 seconds
[2024-03-25T19:11:41.067+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:41.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:11:41.068+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:11:41.068+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:41.207+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:11:41.204+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:11:41.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:11:41.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.158 seconds
[2024-03-25T19:12:06.258+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:12:06.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:12:06.261+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:12:06.260+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:12:06.419+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:12:06.417+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:12:06.420+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:12:06.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.179 seconds
[2024-03-25T19:12:36.557+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:12:36.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:12:36.560+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:12:36.560+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:12:36.725+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:12:36.722+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:12:36.726+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:12:36.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.188 seconds
[2024-03-25T19:13:06.812+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:13:06.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:13:06.816+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:13:06.816+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:13:06.948+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:13:06.946+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:13:06.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:13:06.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.153 seconds
[2024-03-25T19:13:37.101+0000] {processor.py:161} INFO - Started process (PID=462) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:13:37.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:13:37.104+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:13:37.104+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:13:37.261+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:13:37.258+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:13:37.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:13:37.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.178 seconds
[2024-03-25T19:14:07.348+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:14:07.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:14:07.350+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:14:07.350+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:14:07.483+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:14:07.481+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:14:07.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:14:07.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.152 seconds
[2024-03-25T19:14:37.573+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:14:37.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:14:37.575+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:14:37.574+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:14:37.697+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:14:37.695+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:14:37.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:14:37.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.139 seconds
[2024-03-25T19:15:07.803+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:15:07.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:15:07.806+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:15:07.806+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:15:07.985+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:15:07.981+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:15:07.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:15:08.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.200 seconds
[2024-03-25T19:15:38.042+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:15:38.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:15:38.044+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:15:38.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:15:38.200+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:15:38.198+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:15:38.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:15:38.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.176 seconds
[2024-03-25T19:16:08.258+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:16:08.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:16:08.261+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:16:08.260+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:16:08.422+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:16:08.419+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:16:08.422+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:16:08.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.182 seconds
[2024-03-25T19:16:39.465+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:16:39.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:16:39.467+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:16:39.467+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:16:39.619+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:16:39.617+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:16:39.619+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:16:39.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T19:17:09.698+0000] {processor.py:161} INFO - Started process (PID=691) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:17:09.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:17:09.700+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:17:09.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:17:09.847+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:17:09.845+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:17:09.847+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:17:09.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.166 seconds
[2024-03-25T19:17:39.946+0000] {processor.py:161} INFO - Started process (PID=726) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:17:39.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:17:39.948+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:17:39.948+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:17:40.093+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:17:40.090+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:17:40.093+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:17:40.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T19:18:10.182+0000] {processor.py:161} INFO - Started process (PID=761) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:18:10.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:18:10.184+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:18:10.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:18:10.323+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:18:10.321+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:18:10.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:18:10.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.158 seconds
[2024-03-25T19:18:40.430+0000] {processor.py:161} INFO - Started process (PID=796) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:18:40.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:18:40.432+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:18:40.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:18:40.637+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:18:40.633+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:18:40.637+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:18:40.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.229 seconds
[2024-03-25T19:19:10.754+0000] {processor.py:161} INFO - Started process (PID=823) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:19:10.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:19:10.757+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:19:10.756+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:19:10.932+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:19:10.929+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:19:10.932+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:19:10.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.195 seconds
[2024-03-25T19:19:41.059+0000] {processor.py:161} INFO - Started process (PID=858) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:19:41.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:19:41.062+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:19:41.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:19:41.231+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:19:41.229+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:19:41.232+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:19:41.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.189 seconds
[2024-03-25T19:20:11.396+0000] {processor.py:161} INFO - Started process (PID=892) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:20:11.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:20:11.397+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:20:11.397+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:20:11.572+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:20:11.570+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:20:11.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:20:11.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.194 seconds
[2024-03-25T19:20:41.713+0000] {processor.py:161} INFO - Started process (PID=919) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:20:41.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:20:41.716+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:20:41.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:20:41.868+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:20:41.866+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:20:41.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:20:41.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T19:21:12.094+0000] {processor.py:161} INFO - Started process (PID=955) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:21:12.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:21:12.096+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:21:12.096+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:21:12.261+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:21:12.258+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:21:12.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:21:12.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.184 seconds
[2024-03-25T19:21:42.405+0000] {processor.py:161} INFO - Started process (PID=990) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:21:42.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:21:42.408+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:21:42.407+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:21:42.570+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:21:42.568+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:21:42.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:21:42.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T19:22:12.711+0000] {processor.py:161} INFO - Started process (PID=1024) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:22:12.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:22:12.713+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:22:12.713+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:22:12.851+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:22:12.849+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:22:12.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:22:12.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.154 seconds
[2024-03-25T19:22:42.969+0000] {processor.py:161} INFO - Started process (PID=1052) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:22:42.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:22:42.971+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:22:42.970+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:22:43.144+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:22:43.141+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:22:43.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:22:43.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.193 seconds
[2024-03-25T19:23:13.233+0000] {processor.py:161} INFO - Started process (PID=1087) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:23:13.235+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:23:13.236+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:23:13.236+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:23:13.408+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:23:13.405+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:23:13.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:23:13.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.192 seconds
[2024-03-25T19:23:43.492+0000] {processor.py:161} INFO - Started process (PID=1122) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:23:43.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:23:43.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:23:43.493+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:23:43.630+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:23:43.628+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:23:43.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:23:43.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.153 seconds
[2024-03-25T19:24:13.725+0000] {processor.py:161} INFO - Started process (PID=1149) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:24:13.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:24:13.727+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:24:13.726+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:24:13.915+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:24:13.911+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:24:13.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:24:13.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.211 seconds
[2024-03-25T19:24:44.016+0000] {processor.py:161} INFO - Started process (PID=1184) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:24:44.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:24:44.019+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:24:44.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:24:44.201+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:24:44.198+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:24:44.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:24:44.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.203 seconds
[2024-03-25T19:25:14.331+0000] {processor.py:161} INFO - Started process (PID=1219) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:25:14.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:25:14.333+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:25:14.333+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:25:14.519+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:25:14.516+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:25:14.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:25:14.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.204 seconds
[2024-03-25T19:25:44.558+0000] {processor.py:161} INFO - Started process (PID=1246) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:25:44.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:25:44.560+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:25:44.559+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:25:44.688+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:25:44.686+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:25:44.689+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:25:44.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.145 seconds
[2024-03-25T19:26:14.877+0000] {processor.py:161} INFO - Started process (PID=1281) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:26:14.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:26:14.878+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:26:14.878+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:26:15.054+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:26:15.051+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:26:15.054+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:26:15.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.195 seconds
[2024-03-25T19:26:45.241+0000] {processor.py:161} INFO - Started process (PID=1316) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:26:45.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:26:45.244+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:26:45.243+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:26:45.381+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:26:45.379+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:26:45.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:26:45.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.159 seconds
[2024-03-25T19:27:15.533+0000] {processor.py:161} INFO - Started process (PID=1351) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:27:15.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:27:15.535+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:27:15.535+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:27:15.713+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:27:15.710+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:27:15.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:27:15.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.197 seconds
[2024-03-25T19:27:45.880+0000] {processor.py:161} INFO - Started process (PID=1378) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:27:45.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:27:45.883+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:27:45.882+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:27:46.047+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:27:46.044+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:27:46.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:27:46.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.186 seconds
[2024-03-25T19:28:16.218+0000] {processor.py:161} INFO - Started process (PID=1413) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:28:16.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:28:16.221+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:28:16.220+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:28:16.363+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:28:16.361+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:28:16.364+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:28:16.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.163 seconds
[2024-03-25T19:28:46.505+0000] {processor.py:161} INFO - Started process (PID=1448) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:28:46.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:28:46.507+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:28:46.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:28:46.784+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:28:46.782+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:28:46.785+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:28:46.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.298 seconds
[2024-03-25T19:29:16.905+0000] {processor.py:161} INFO - Started process (PID=1475) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:29:16.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:29:16.908+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:29:16.907+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:29:17.070+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:29:17.068+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:29:17.071+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:29:17.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T19:29:47.187+0000] {processor.py:161} INFO - Started process (PID=1510) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:29:47.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:29:47.189+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:29:47.189+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:29:47.386+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:29:47.384+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:29:47.387+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:29:47.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.217 seconds
[2024-03-25T19:30:17.452+0000] {processor.py:161} INFO - Started process (PID=1545) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:30:17.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:30:17.454+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:30:17.453+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:30:17.631+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:30:17.628+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:30:17.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:30:17.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.196 seconds
[2024-03-25T19:30:47.703+0000] {processor.py:161} INFO - Started process (PID=1572) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:30:47.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:30:47.707+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:30:47.706+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:30:47.896+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:30:47.894+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:30:47.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:30:47.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.213 seconds
[2024-03-25T19:31:18.043+0000] {processor.py:161} INFO - Started process (PID=1607) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:31:18.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:31:18.045+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:31:18.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:31:18.225+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:31:18.222+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:31:18.226+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:31:18.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.204 seconds
[2024-03-25T19:31:48.358+0000] {processor.py:161} INFO - Started process (PID=1642) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:31:48.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:31:48.360+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:31:48.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:31:48.545+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:31:48.542+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:31:48.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:31:48.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.211 seconds
[2024-03-25T19:32:18.693+0000] {processor.py:161} INFO - Started process (PID=1669) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:32:18.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:32:18.696+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:32:18.695+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:32:18.864+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:32:18.861+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:32:18.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:32:18.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.190 seconds
[2024-03-25T19:32:48.999+0000] {processor.py:161} INFO - Started process (PID=1704) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:32:49.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:32:49.001+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:32:49.001+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:32:49.180+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:32:49.178+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:32:49.181+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:32:49.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.200 seconds
[2024-03-25T19:33:19.313+0000] {processor.py:161} INFO - Started process (PID=1739) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:33:19.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:33:19.316+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:33:19.315+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:33:19.465+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:33:19.463+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:33:19.466+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:33:19.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.170 seconds
[2024-03-25T19:33:49.552+0000] {processor.py:161} INFO - Started process (PID=1774) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:33:49.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:33:49.554+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:33:49.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:33:49.721+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:33:49.718+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:33:49.722+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:33:49.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.190 seconds
[2024-03-25T19:34:19.846+0000] {processor.py:161} INFO - Started process (PID=1800) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:34:19.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:34:19.851+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:34:19.850+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:34:20.028+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:34:20.025+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:34:20.028+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:34:20.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.200 seconds
[2024-03-25T19:34:50.213+0000] {processor.py:161} INFO - Started process (PID=1835) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:34:50.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:34:50.216+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:34:50.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:34:50.424+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:34:50.421+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:34:50.425+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:34:50.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.235 seconds
[2024-03-25T19:35:20.500+0000] {processor.py:161} INFO - Started process (PID=1870) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:35:20.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:35:20.501+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:35:20.501+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:35:20.651+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:35:20.649+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:35:20.651+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:35:20.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.168 seconds
[2024-03-25T19:35:50.793+0000] {processor.py:161} INFO - Started process (PID=1897) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:35:50.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:35:50.796+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:35:50.795+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:35:50.976+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:35:50.973+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:35:50.976+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:35:50.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.202 seconds
[2024-03-25T19:36:21.080+0000] {processor.py:161} INFO - Started process (PID=1932) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:36:21.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:36:21.083+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:36:21.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:36:21.264+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:36:21.261+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:36:21.264+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:36:21.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.200 seconds
[2024-03-25T19:36:51.335+0000] {processor.py:161} INFO - Started process (PID=1967) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:36:51.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:36:51.336+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:36:51.336+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:36:51.500+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:36:51.497+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:36:51.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:36:51.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.183 seconds
[2024-03-25T19:37:21.623+0000] {processor.py:161} INFO - Started process (PID=1999) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:37:21.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:37:21.625+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:37:21.624+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:37:21.795+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:37:21.793+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:37:21.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:37:21.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.189 seconds
[2024-03-25T19:37:51.854+0000] {processor.py:161} INFO - Started process (PID=2034) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:37:51.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:37:51.855+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:37:51.855+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:37:51.997+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:37:51.994+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:37:51.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:37:52.012+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.161 seconds
[2024-03-25T19:38:22.093+0000] {processor.py:161} INFO - Started process (PID=2064) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:38:22.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:38:22.095+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:38:22.095+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:38:22.303+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:38:22.300+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:38:22.303+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:38:22.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.229 seconds
[2024-03-25T19:38:52.373+0000] {processor.py:161} INFO - Started process (PID=2091) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:38:52.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:38:52.375+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:38:52.375+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:38:52.522+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:38:52.519+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:38:52.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:38:52.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.169 seconds
[2024-03-25T19:39:22.636+0000] {processor.py:161} INFO - Started process (PID=2126) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:39:22.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:39:22.638+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:39:22.637+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:39:22.800+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:39:22.797+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:39:22.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:39:22.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T19:39:52.923+0000] {processor.py:161} INFO - Started process (PID=2161) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:39:52.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:39:52.925+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:39:52.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:39:53.062+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:39:53.060+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:39:53.063+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:39:53.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.156 seconds
[2024-03-25T19:40:23.216+0000] {processor.py:161} INFO - Started process (PID=2188) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:40:23.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:40:23.222+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:40:23.222+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:40:23.397+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:40:23.394+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:40:23.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:40:23.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.199 seconds
[2024-03-25T19:40:53.477+0000] {processor.py:161} INFO - Started process (PID=2222) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:40:53.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:40:53.479+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:40:53.479+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:40:53.665+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:40:53.662+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:40:53.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:40:53.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.209 seconds
[2024-03-25T19:41:23.760+0000] {processor.py:161} INFO - Started process (PID=2257) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:41:23.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:41:23.762+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:41:23.762+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:41:23.957+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:41:23.954+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:41:23.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:41:23.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.214 seconds
[2024-03-25T19:41:54.118+0000] {processor.py:161} INFO - Started process (PID=2284) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:41:54.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:41:54.121+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:41:54.120+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:41:54.299+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:41:54.297+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:41:54.300+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:41:54.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.201 seconds
[2024-03-25T19:42:24.422+0000] {processor.py:161} INFO - Started process (PID=2319) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:42:24.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:42:24.424+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:42:24.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:42:24.583+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:42:24.581+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:42:24.583+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:42:24.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.177 seconds
[2024-03-25T19:42:54.676+0000] {processor.py:161} INFO - Started process (PID=2355) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:42:54.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:42:54.678+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:42:54.677+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:42:54.834+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:42:54.825+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:42:54.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:42:54.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.181 seconds
[2024-03-25T19:43:24.931+0000] {processor.py:161} INFO - Started process (PID=2390) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:43:24.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:43:24.933+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:43:24.933+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:43:25.106+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:43:25.104+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:43:25.107+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:43:25.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.192 seconds
[2024-03-25T19:43:55.308+0000] {processor.py:161} INFO - Started process (PID=2417) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:43:55.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:43:55.311+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:43:55.310+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:43:55.493+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:43:55.490+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:43:55.493+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:43:55.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.203 seconds
[2024-03-25T19:44:25.567+0000] {processor.py:161} INFO - Started process (PID=2452) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:44:25.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:44:25.569+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:44:25.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:44:25.717+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:44:25.715+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:44:25.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:44:25.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.167 seconds
[2024-03-25T19:44:55.810+0000] {processor.py:161} INFO - Started process (PID=2487) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:44:55.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:44:55.812+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:44:55.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:44:55.995+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:44:55.993+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:44:55.996+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:44:56.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.203 seconds
[2024-03-25T19:45:26.100+0000] {processor.py:161} INFO - Started process (PID=2514) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:45:26.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:45:26.102+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:45:26.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:45:26.239+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:45:26.237+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:45:26.239+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:45:26.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T19:45:56.361+0000] {processor.py:161} INFO - Started process (PID=2549) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:45:56.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:45:56.364+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:45:56.363+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:45:56.522+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:45:56.520+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:45:56.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:45:56.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.178 seconds
[2024-03-25T19:46:26.609+0000] {processor.py:161} INFO - Started process (PID=2584) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:46:26.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:46:26.611+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:46:26.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:46:26.853+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:46:26.852+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:46:26.854+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:46:26.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.260 seconds
[2024-03-25T19:46:56.921+0000] {processor.py:161} INFO - Started process (PID=2623) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:46:56.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:46:56.922+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:46:56.922+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:46:57.088+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:46:57.085+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:46:57.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:46:57.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.183 seconds
[2024-03-25T19:47:01.950+0000] {processor.py:161} INFO - Started process (PID=2630) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:01.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:47:01.952+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:47:01.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:02.103+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:47:02.100+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:47:02.103+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:02.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.171 seconds
[2024-03-25T19:47:32.187+0000] {processor.py:161} INFO - Started process (PID=2665) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:32.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:47:32.189+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:47:32.188+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:32.322+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:47:32.320+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:47:32.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:32.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.152 seconds
[2024-03-25T19:47:36.397+0000] {processor.py:161} INFO - Started process (PID=2671) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:36.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:47:36.400+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:47:36.399+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:36.553+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:47:36.550+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:47:36.553+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:47:36.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T19:48:06.628+0000] {processor.py:161} INFO - Started process (PID=2707) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:06.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:48:06.631+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:48:06.630+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:06.789+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:48:06.787+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:48:06.790+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:06.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.178 seconds
[2024-03-25T19:48:36.932+0000] {processor.py:161} INFO - Started process (PID=2734) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:36.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:48:36.935+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:48:36.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:37.094+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:48:37.091+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:48:37.094+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:37.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.289 seconds
[2024-03-25T19:48:53.071+0000] {processor.py:161} INFO - Started process (PID=2756) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:53.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:48:53.074+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:48:53.073+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:53.319+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:48:53.318+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:48:53.320+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:48:53.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.265 seconds
[2024-03-25T19:49:23.522+0000] {processor.py:161} INFO - Started process (PID=2791) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:49:23.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:49:23.524+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:49:23.524+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:49:23.664+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:49:23.662+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:49:23.664+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:49:23.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.158 seconds
[2024-03-25T19:49:53.737+0000] {processor.py:161} INFO - Started process (PID=2818) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:49:53.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:49:53.742+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:49:53.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:49:53.892+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:49:53.890+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:49:53.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:49:53.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T19:50:23.963+0000] {processor.py:161} INFO - Started process (PID=2853) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:50:23.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:50:23.966+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:50:23.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:50:24.101+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:50:24.099+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:50:24.101+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:50:24.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.155 seconds
[2024-03-25T19:50:54.227+0000] {processor.py:161} INFO - Started process (PID=2888) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:50:54.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:50:54.230+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:50:54.230+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:50:54.402+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:50:54.399+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:50:54.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:50:54.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.305 seconds
[2024-03-25T19:51:25.470+0000] {processor.py:161} INFO - Started process (PID=2923) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:51:25.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:51:25.472+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:51:25.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:51:25.722+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:51:25.720+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:51:25.722+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:51:25.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.268 seconds
[2024-03-25T19:51:56.752+0000] {processor.py:161} INFO - Started process (PID=2950) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:51:56.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:51:56.754+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:51:56.754+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:51:57.050+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:51:57.048+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:51:57.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:51:57.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.316 seconds
[2024-03-25T19:52:28.003+0000] {processor.py:161} INFO - Started process (PID=2985) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:52:28.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:52:28.007+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:52:28.006+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:52:28.166+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:52:28.164+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:52:28.167+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:52:28.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.180 seconds
[2024-03-25T19:52:58.284+0000] {processor.py:161} INFO - Started process (PID=3020) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:52:58.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:52:58.286+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:52:58.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:52:58.465+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:52:58.461+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:52:58.465+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:52:58.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.200 seconds
[2024-03-25T19:53:28.528+0000] {processor.py:161} INFO - Started process (PID=3055) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:53:28.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:53:28.531+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:53:28.530+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:53:28.688+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:53:28.686+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:53:28.689+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:53:28.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.371 seconds
[2024-03-25T19:53:59.726+0000] {processor.py:161} INFO - Started process (PID=3082) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:53:59.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:53:59.728+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:53:59.728+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:53:59.962+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:53:59.960+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:53:59.963+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:53:59.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.252 seconds
[2024-03-25T19:54:30.025+0000] {processor.py:161} INFO - Started process (PID=3117) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:54:30.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:54:30.028+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:54:30.028+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:54:30.315+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:54:30.313+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:54:30.316+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:54:30.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.308 seconds
[2024-03-25T19:55:01.208+0000] {processor.py:161} INFO - Started process (PID=3152) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:55:01.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:55:01.210+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:55:01.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:55:01.433+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:55:01.431+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:55:01.433+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:55:01.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.239 seconds
[2024-03-25T19:55:31.514+0000] {processor.py:161} INFO - Started process (PID=3192) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:55:31.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:55:31.516+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:55:31.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:55:31.681+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:55:31.679+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:55:31.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:55:31.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.185 seconds
[2024-03-25T19:56:01.785+0000] {processor.py:161} INFO - Started process (PID=3219) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:56:01.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:56:01.787+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:56:01.787+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:56:01.988+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:56:01.985+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:56:01.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:56:02.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.349 seconds
[2024-03-25T19:56:32.961+0000] {processor.py:161} INFO - Started process (PID=3254) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:56:32.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:56:32.963+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:56:32.962+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:56:33.234+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:56:33.232+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:56:33.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:56:33.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.287 seconds
[2024-03-25T19:57:04.207+0000] {processor.py:161} INFO - Started process (PID=3290) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:57:04.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:57:04.210+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:57:04.209+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:57:04.440+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:57:04.438+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:57:04.440+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:57:04.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.250 seconds
[2024-03-25T19:57:34.534+0000] {processor.py:161} INFO - Started process (PID=3324) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:57:34.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:57:34.536+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:57:34.536+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:57:34.834+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:57:34.832+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:57:34.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:57:34.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.315 seconds
[2024-03-25T19:58:05.705+0000] {processor.py:161} INFO - Started process (PID=3352) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:58:05.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:58:05.707+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:58:05.706+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:58:05.854+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:58:05.852+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:58:05.854+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:58:05.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.166 seconds
[2024-03-25T19:58:36.020+0000] {processor.py:161} INFO - Started process (PID=3387) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:58:36.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:58:36.022+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:58:36.021+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:58:36.176+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:58:36.174+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:58:36.177+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:58:36.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.262 seconds
[2024-03-25T19:59:07.281+0000] {processor.py:161} INFO - Started process (PID=3422) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:07.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:59:07.286+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:59:07.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:07.568+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:59:07.564+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:59:07.568+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:07.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.320 seconds
[2024-03-25T19:59:28.724+0000] {processor.py:161} INFO - Started process (PID=3444) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:28.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:59:28.729+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:59:28.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:28.948+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:59:28.946+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:59:28.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:28.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.239 seconds
[2024-03-25T19:59:29.746+0000] {processor.py:161} INFO - Started process (PID=3450) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:29.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T19:59:29.748+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:59:29.748+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:29.950+0000] {logging_mixin.py:188} INFO - [2024-03-25T19:59:29.948+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T19:59:29.950+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T19:59:29.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.219 seconds
[2024-03-25T20:00:00.980+0000] {processor.py:161} INFO - Started process (PID=3486) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:00.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:00:00.982+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:00:00.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:01.341+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:00:01.339+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:00:01.341+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:01.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.382 seconds
[2024-03-25T20:00:22.198+0000] {processor.py:161} INFO - Started process (PID=3512) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:22.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:00:22.201+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:00:22.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:22.402+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:00:22.398+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:00:22.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:22.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.227 seconds
[2024-03-25T20:00:52.487+0000] {processor.py:161} INFO - Started process (PID=3540) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:52.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:00:52.489+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:00:52.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:52.658+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:00:52.655+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:00:52.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:00:52.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.304 seconds
[2024-03-25T20:01:23.742+0000] {processor.py:161} INFO - Started process (PID=3575) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:01:23.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:01:23.745+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:01:23.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:01:23.979+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:01:23.978+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:01:23.980+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:01:23.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.254 seconds
[2024-03-25T20:01:54.085+0000] {processor.py:161} INFO - Started process (PID=3610) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:01:54.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:01:54.087+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:01:54.087+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:01:54.408+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:01:54.406+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:01:54.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:01:54.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.341 seconds
[2024-03-25T20:02:25.321+0000] {processor.py:161} INFO - Started process (PID=3645) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:02:25.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:02:25.323+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:02:25.323+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:02:25.649+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:02:25.646+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:02:25.650+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:02:25.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.346 seconds
[2024-03-25T20:02:56.582+0000] {processor.py:161} INFO - Started process (PID=3672) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:02:56.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:02:56.585+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:02:56.585+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:02:56.863+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:02:56.862+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:02:56.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:02:56.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.297 seconds
[2024-03-25T20:03:27.849+0000] {processor.py:161} INFO - Started process (PID=3706) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:03:27.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:03:27.851+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:03:27.851+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:03:28.099+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:03:28.097+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:03:28.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:03:28.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.266 seconds
[2024-03-25T20:03:59.136+0000] {processor.py:161} INFO - Started process (PID=3740) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:03:59.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:03:59.139+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:03:59.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:03:59.398+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:03:59.396+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:03:59.398+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:03:59.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.277 seconds
[2024-03-25T20:04:30.352+0000] {processor.py:161} INFO - Started process (PID=3775) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:04:30.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:04:30.355+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:04:30.354+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:04:30.643+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:04:30.641+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:04:30.643+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:04:30.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.307 seconds
[2024-03-25T20:05:01.562+0000] {processor.py:161} INFO - Started process (PID=3802) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:05:01.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:05:01.565+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:05:01.565+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:05:01.862+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:05:01.860+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:05:01.862+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:05:01.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.320 seconds
[2024-03-25T20:05:32.898+0000] {processor.py:161} INFO - Started process (PID=3837) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:05:32.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:05:32.901+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:05:32.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:05:33.074+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:05:33.071+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:05:33.074+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:05:33.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.197 seconds
[2024-03-25T20:06:04.174+0000] {processor.py:161} INFO - Started process (PID=3872) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:06:04.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:06:04.177+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:06:04.177+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:06:04.460+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:06:04.458+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:06:04.461+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:06:04.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.302 seconds
[2024-03-25T20:06:35.384+0000] {processor.py:161} INFO - Started process (PID=3907) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:06:35.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:06:35.386+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:06:35.385+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:06:35.595+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:06:35.593+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:06:35.595+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:06:35.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.225 seconds
[2024-03-25T20:08:20.376+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:08:20.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:08:20.378+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:08:20.378+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:08:21.033+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:08:21.031+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:08:21.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:08:21.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.673 seconds
[2024-03-25T20:08:51.920+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:08:51.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:08:51.923+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:08:51.922+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:08:52.082+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:08:52.079+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:08:52.082+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:08:52.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.179 seconds
[2024-03-25T20:09:22.204+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:09:22.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:09:22.206+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:09:22.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:09:22.364+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:09:22.362+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:09:22.364+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:09:22.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.175 seconds
[2024-03-25T20:09:52.513+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:09:52.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:09:52.516+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:09:52.516+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:09:52.700+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:09:52.696+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:09:52.700+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:09:52.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.205 seconds
[2024-03-25T20:10:22.904+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:10:22.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sales_data_pipeline.py for tasks to queue
[2024-03-25T20:10:22.907+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:10:22.907+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:10:23.083+0000] {logging_mixin.py:188} INFO - [2024-03-25T20:10:23.080+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/sales_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/sales_data_pipeline.py", line 22, in <module>
    from common import get_weather_info
  File "/opt/airflow/dags/common.py", line 97, in <module>
    build_exec_pipeline_sales_data(sales_data_df,users_data_df)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 367, in __call__
    op = self.operator_class(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 445, in apply_defaults
    self.set_xcomargs_dependencies()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 1166, in set_xcomargs_dependencies
    XComArg.apply_upstream_relationship(self, arg)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom_arg.py", line 129, in apply_upstream_relationship
    op.set_upstream(operator)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 232, in _set_relatives
    raise AirflowException(
airflow.exceptions.AirflowException: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(_PythonDecoratedOperator): build_exec_pipeline_sales_data>, <Task(_PythonDecoratedOperator): get_sales_data_from_csv>]
[2024-03-25T20:10:23.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/sales_data_pipeline.py
[2024-03-25T20:10:23.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sales_data_pipeline.py took 0.200 seconds
